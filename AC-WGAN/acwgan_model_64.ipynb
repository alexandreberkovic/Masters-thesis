{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fccf255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Creates batches of images to feed into the training network conditioned by genre, uses upsampling when creating batches to account for uneven distributions '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Creates batches of images to feed into the training network conditioned by genre, uses upsampling when creating batches to account for uneven distributions \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5126576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow-gpu==1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a9f86cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5079567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dimension of images you want to be passed in to the network\n",
    "DIM = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a59ffae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your own path to images\n",
    "# src_img_path  = Path('/home/ec2-user/SageMaker/genre-128')\n",
    "src_img_path  = Path('/home/ec2-user/SageMaker/portrait_landscape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28e761bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '.ipynb_checkpoints', '0']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(src_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f607533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14971"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(os.path.join(src_img_path,'1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62a6cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary should be updated to hold the absolute number of images associated with each genre used during training\n",
    "styles = {\n",
    "    \"portraits\": 14981,\n",
    "    \"landscapes\": 14971\n",
    "}\n",
    "\n",
    "styleNum = {\n",
    "    \"portraits\": 0,\n",
    "    \"landscapes\": 1\n",
    "}\n",
    "    \n",
    "curPos = {\n",
    "    \"portraits\": 0,\n",
    "    \"landscapes\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b623c515",
   "metadata": {},
   "outputs": [],
   "source": [
    "testNums = {}\n",
    "trainNums = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1dd52166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test set of images made up of 1/20 of the images (per genre)\n",
    "for k, v in styles.items():\n",
    "    # put a twentieth of paintings in here\n",
    "    nums = range(v)\n",
    "    random.shuffle(list(nums))\n",
    "    testNums[k] = nums[0 : v // 20]\n",
    "    trainNums[k] = nums[v // 20 :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ab11d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf_gen(gen):\n",
    "    while True:\n",
    "        for (images, labels) in gen():\n",
    "            yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "130d0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator(files, batch_size, n_classes): # add genre parameter\n",
    "    if batch_size % n_classes != 0:\n",
    "        raise ValueError(\n",
    "            \"Batch size {} must be divisible by num classes {}\".format(batch_size, n_classes)\n",
    "        )\n",
    "\n",
    "    class_batch = batch_size // n_classes\n",
    "\n",
    "    generators = []\n",
    "\n",
    "    def get_epoch():\n",
    "\n",
    "        while True:\n",
    "\n",
    "            images = np.zeros((batch_size, 3, DIM, DIM), dtype=\"int32\")\n",
    "            labels = np.zeros((batch_size, n_classes))\n",
    "            n = 0\n",
    "            for style in styles:\n",
    "#             for style in genre:\n",
    "                styleLabel = styleNum[style]\n",
    "                curr = curPos[style]\n",
    "                for _ in range(class_batch):\n",
    "                    if curr == styles[style]:\n",
    "                        curr = 0\n",
    "                        random.shuffle(list(files[style]))\n",
    "                    img_path = str(Path(src_img_path, str(styleLabel), str(curr) + \".png\"))\n",
    "                    image = Image.open(img_path).convert(mode=\"RGB\")\n",
    "                    image = np.asarray(image)\n",
    "\n",
    "                    images[n % batch_size] = image.transpose(2, 0, 1)\n",
    "                    labels[n % batch_size, int(styleLabel)] = 1\n",
    "                    n += 1\n",
    "                    curr += 1\n",
    "                curPos[style] = curr\n",
    "\n",
    "            # randomize things but keep relationship between a conditioning vector and its associated image\n",
    "            rng_state = np.random.get_state()\n",
    "            np.random.shuffle(images)\n",
    "            np.random.set_state(rng_state)\n",
    "            np.random.shuffle(labels)\n",
    "            yield (images, labels)\n",
    "\n",
    "    return get_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da957475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(batch_size):\n",
    "    return (\n",
    "        make_generator(trainNums, batch_size, len(styles)),\n",
    "        make_generator(testNums, batch_size, len(styles)),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c4a8d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import time\n",
    "import functools\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tflib as lib\n",
    "import tflib.ops.linear\n",
    "import tflib.ops.conv2d\n",
    "import tflib.ops.batchnorm\n",
    "import tflib.ops.deconv2d\n",
    "import tflib.save_images\n",
    "# import tflib.wikiart_genre\n",
    "import tflib.ops.layernorm\n",
    "import tflib.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f7c463a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade tensorflow-gpu==1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a0be83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df7b28ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.15.5\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.gpu_device_name())\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "49b731bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "81870fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uppercase local vars:\n",
      "\tBATCH_SIZE: 84\n",
      "\tCLASSES: 2\n",
      "\tCRITIC_ITERS: 5\n",
      "\tDEVICES: ['/gpu:0']\n",
      "\tDIM: 64\n",
      "\tITERS: 200000\n",
      "\tLAMBDA: 10\n",
      "\tMODE: acwgan\n",
      "\tN_GPUS: 1\n",
      "\tOUTPUT_DIM: 12288\n",
      "\tPREITERATIONS: 2000\n"
     ]
    }
   ],
   "source": [
    "MODE = \"acwgan\"  # dcgan, wgan, wgan-gp, lsgan\n",
    "genre = ['portraits','landscapes']\n",
    "DIM = 64  # Model dimensionality\n",
    "CRITIC_ITERS = 5  # How many iterations to train the critic for, increase it to 50 later\n",
    "N_GPUS = 1  # Number of GPUs\n",
    "BATCH_SIZE = 84  # Batch size. Must be a multiple of CLASSES and N_GPUS\n",
    "ITERS = 200000  # How many iterations to train for\n",
    "LAMBDA = 10  # Gradient penalty lambda hyperparameter\n",
    "OUTPUT_DIM = DIM * DIM * 3  # Number of pixels in each image\n",
    "CLASSES = len(genre)  # Number of classes, for genres probably 14\n",
    "PREITERATIONS = 2000  # Number of preiteration training cycles to run\n",
    "lib.print_model_settings(locals().copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ebe810b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that directory exists where ground truth and plots will be saved to.\n",
    "Path('generated').mkdir(parents=True, exist_ok=True)\n",
    "Path('models').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "343c3b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeneratorAndDiscriminator():\n",
    "    return kACGANGenerator, kACGANDiscriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d8cefde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICES = [\"/gpu:{}\".format(i) for i in range(N_GPUS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "270526fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeakyReLU(x, alpha=0.2):\n",
    "    return tf.maximum(alpha * x, x)\n",
    "\n",
    "\n",
    "def ReLULayer(name, n_in, n_out, inputs):\n",
    "    output = lib.ops.linear.Linear(\n",
    "        name + \".Linear\", n_in, n_out, inputs, initialization=\"he\"\n",
    "    )\n",
    "    return tf.nn.relu(output)\n",
    "\n",
    "\n",
    "def LeakyReLULayer(name, n_in, n_out, inputs):\n",
    "    output = lib.ops.linear.Linear(\n",
    "        name + \".Linear\", n_in, n_out, inputs, initialization=\"he\"\n",
    "    )\n",
    "    return LeakyReLU(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f50ad824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Batchnorm(name, axes, inputs):\n",
    "\n",
    "    if (\"Discriminator\" in name) and (MODE == \"wgan-gp\" or MODE == \"acwgan\"):\n",
    "        if axes != [0, 2, 3]:\n",
    "            raise Exception(\"Layernorm over non-standard axes is unsupported\")\n",
    "        return lib.ops.layernorm.Layernorm(name, [1, 2, 3], inputs)\n",
    "    else:\n",
    "        return lib.ops.batchnorm.Batchnorm(name, axes, inputs, fused=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "43541611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixcnn_gated_nonlinearity(name, output_dim, a, b, c=None, d=None):\n",
    "    if c is not None and d is not None:\n",
    "        a = a + c\n",
    "        b = b + d\n",
    "\n",
    "    result = tf.sigmoid(a) * tf.tanh(b)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d269055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SubpixelConv2D(*args, **kwargs):\n",
    "    kwargs[\"output_dim\"] = 4 * kwargs[\"output_dim\"]\n",
    "    output = lib.ops.conv2d.Conv2D(*args, **kwargs)\n",
    "    output = tf.transpose(output, [0, 2, 3, 1])\n",
    "    output = tf.depth_to_space(output, 2)\n",
    "    output = tf.transpose(output, [0, 3, 1, 2])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "69325534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResidualBlock(\n",
    "    name, input_dim, output_dim, filter_size, inputs, resample=None, he_init=True\n",
    "):\n",
    "    \"\"\"\n",
    "    resample: None, 'down', or 'up'\n",
    "    \"\"\"\n",
    "    if resample == \"down\":\n",
    "        conv_shortcut = functools.partial(lib.ops.conv2d.Conv2D, stride=2)\n",
    "        conv_1 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim, output_dim=input_dim // 2\n",
    "        )\n",
    "        conv_1b = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D,\n",
    "            input_dim=input_dim // 2,\n",
    "            output_dim=output_dim // 2,\n",
    "            stride=2,\n",
    "        )\n",
    "        conv_2 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=output_dim // 2, output_dim=output_dim\n",
    "        )\n",
    "    elif resample == \"up\":\n",
    "        conv_shortcut = SubpixelConv2D\n",
    "        conv_1 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim, output_dim=input_dim // 2\n",
    "        )\n",
    "        conv_1b = functools.partial(\n",
    "            lib.ops.deconv2d.Deconv2D,\n",
    "            input_dim=input_dim // 2,\n",
    "            output_dim=output_dim // 2,\n",
    "        )\n",
    "        conv_2 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=output_dim // 2, output_dim=output_dim\n",
    "        )\n",
    "    elif resample == None:\n",
    "        conv_shortcut = lib.ops.conv2d.Conv2D\n",
    "        conv_1 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim, output_dim=input_dim // 2\n",
    "        )\n",
    "        conv_1b = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim // 2, output_dim=output_dim // 2\n",
    "        )\n",
    "        conv_2 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim // 2, output_dim=output_dim\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"invalid resample value\")\n",
    "\n",
    "    if output_dim == input_dim and resample == None:\n",
    "        shortcut = inputs  # Identity skip-connection\n",
    "    else:\n",
    "        shortcut = conv_shortcut(\n",
    "            name + \".Shortcut\",\n",
    "            input_dim=input_dim,\n",
    "            output_dim=output_dim,\n",
    "            filter_size=1,\n",
    "            he_init=False,\n",
    "            biases=True,\n",
    "            inputs=inputs,\n",
    "        )\n",
    "\n",
    "    output = inputs\n",
    "    output = tf.nn.relu(output)\n",
    "    output = conv_1(\n",
    "        name + \".Conv1\", filter_size=1, inputs=output, he_init=he_init, weightnorm=False\n",
    "    )\n",
    "    output = tf.nn.relu(output)\n",
    "    output = conv_1b(\n",
    "        name + \".Conv1B\",\n",
    "        filter_size=filter_size,\n",
    "        inputs=output,\n",
    "        he_init=he_init,\n",
    "        weightnorm=False,\n",
    "    )\n",
    "    output = tf.nn.relu(output)\n",
    "    output = conv_2(\n",
    "        name + \".Conv2\",\n",
    "        filter_size=1,\n",
    "        inputs=output,\n",
    "        he_init=he_init,\n",
    "        weightnorm=False,\n",
    "        biases=False,\n",
    "    )\n",
    "    output = Batchnorm(name + \".BN\", [0, 2, 3], output)\n",
    "\n",
    "    return shortcut + (0.3 * output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d291d489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kACGANGenerator(\n",
    "    n_samples,\n",
    "    numClasses,\n",
    "    labels,\n",
    "    noise=None,\n",
    "    dim=DIM,\n",
    "    bn=True,\n",
    "    nonlinearity=tf.nn.relu,\n",
    "    condition=None,\n",
    "):\n",
    "    lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.linear.set_weights_stdev(0.02)\n",
    "    if noise is None:\n",
    "        noise = tf.random_normal([n_samples, 128])\n",
    "\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    noise = tf.concat([noise, labels], 1)\n",
    "\n",
    "    output = lib.ops.linear.Linear(\n",
    "        \"Generator.Input\", 128 + numClasses, 8 * 4 * 4 * dim * 2, noise\n",
    "    )  # probs need to recalculate dimensions\n",
    "    print('Generator output 1: ', output)\n",
    "    output = tf.reshape(output, [-1, 8 * dim * 2, 4, 4])\n",
    "#     output = tf.reshape(output, [-1, dim , 4, 4])\n",
    "    print('Generator output 1 reshape: ', output, output.shape)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN1\", [0, 2, 3], output)\n",
    "        print('Generator output 1 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond1\", numClasses, 8 * 4 * 4 * dim * 2, labels, biases=False\n",
    "    )\n",
    "    condition = tf.reshape(condition, [-1, 8 * dim * 2, 4, 4])\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl1\",\n",
    "        8 * dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2],\n",
    "        condition[:, ::2],\n",
    "        condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 1 final: ', output)\n",
    "    print('Structure 1: ', 8 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "#######################\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.2\", 8 * dim, 4 * dim * 2, 5, output)\n",
    "    print('Generator output 2: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN2\", [0, 2, 3], output)\n",
    "        print('Generator output 2 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond2\", numClasses, 4 * 8 * 8 * dim * 2, labels\n",
    "    )\n",
    "    condition = tf.reshape(condition, [-1, 4 * dim * 2, 8, 8])\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl2\",\n",
    "        4 * dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2],\n",
    "        condition[:, ::2],\n",
    "        condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 2 final: ', output)\n",
    "    print('Structure 2: ', 4 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "#######################\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.3\", 4 * dim, 2 * dim * 2, 5, output)\n",
    "    print('Generator output 3: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN3\", [0, 2, 3], output)\n",
    "        print('Generator output 3 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond3\", numClasses, 2 * 16 * 16 * dim * 2, labels\n",
    "    )\n",
    "    condition = tf.reshape(condition, [-1, 2 * dim * 2, 16, 16])\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl3\",\n",
    "        2 * dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2],\n",
    "        condition[:, ::2],\n",
    "        condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 3 final: ', output)\n",
    "    print('Structure 3: ', 2 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "#######################\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.4\", 2 * dim, dim * 2, 5, output)\n",
    "    print('Generator output 4: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN4\", [0, 2, 3], output)\n",
    "        print('Generator output 4 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond4\", numClasses, 32 * 32 * dim * 2, labels\n",
    "    )\n",
    "    condition = tf.reshape(condition, [-1, 2 * dim, 32, 32])\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl4\",\n",
    "        dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2],\n",
    "        condition[:, ::2],\n",
    "        condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 4 final: ', output)\n",
    "    print('Structure 4: ', dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "#######################\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.5\", dim, 3, 5, output)\n",
    "    print('Generator output 6: ', output)\n",
    "    output = tf.tanh(output)\n",
    "    print('Generator output final: ', output)\n",
    "    lib.ops.conv2d.unset_weights_stdev()\n",
    "    lib.ops.deconv2d.unset_weights_stdev()\n",
    "    lib.ops.linear.unset_weights_stdev()\n",
    "\n",
    "    return tf.reshape(output, [-1, OUTPUT_DIM]), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "17902a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def kACGANDiscriminator(inputs, numClasses, dim=DIM, bn=True, nonlinearity=LeakyReLU):\n",
    "#     output = tf.reshape(inputs, [-1, 3, dim, dim])\n",
    "\n",
    "#     lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.linear.set_weights_stdev(0.02)\n",
    "\n",
    "#     output = lib.ops.conv2d.Conv2D(\"Discriminator.1\", 3, dim, 5, output, stride=2)\n",
    "#     output = nonlinearity(output)\n",
    "\n",
    "#     output = lib.ops.conv2d.Conv2D(\"Discriminator.2\", dim, 2 * dim, 5, output, stride=2)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN2\", [0, 2, 3], output)\n",
    "#     output = nonlinearity(output)\n",
    "\n",
    "#     output = lib.ops.conv2d.Conv2D(\n",
    "#         \"Discriminator.3\", 2 * dim, 4 * dim, 5, output, stride=2\n",
    "#     )\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN3\", [0, 2, 3], output)\n",
    "#     output = nonlinearity(output)\n",
    "\n",
    "#     output = lib.ops.conv2d.Conv2D(\n",
    "#         \"Discriminator.4\", 4 * dim, 8 * dim, 5, output, stride=2\n",
    "#     )\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN4\", [0, 2, 3], output)\n",
    "#     output = nonlinearity(output)\n",
    "#     finalLayer = tf.reshape(output, [-1, 4 * 4 * 8 * dim])\n",
    "\n",
    "#     sourceOutput = lib.ops.linear.Linear(\n",
    "#         \"Discriminator.sourceOutput\", 4 * 4 * 8 * dim, 1, finalLayer\n",
    "#     )\n",
    "\n",
    "#     classOutput = lib.ops.linear.Linear(\n",
    "#         \"Discriminator.classOutput\", 4 * 4 * 8 * dim, numClasses, finalLayer\n",
    "#     )\n",
    "\n",
    "#     lib.ops.conv2d.unset_weights_stdev()\n",
    "#     lib.ops.deconv2d.unset_weights_stdev()\n",
    "#     lib.ops.linear.unset_weights_stdev()\n",
    "\n",
    "#     return (tf.reshape(sourceOutput, [-1]), tf.reshape(classOutput, [-1, numClasses]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b1352c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kACGANDiscriminator(inputs, numClasses, dim=DIM, bn=True, nonlinearity=LeakyReLU):\n",
    "    output = tf.reshape(inputs, [-1, 3, dim, dim])\n",
    "\n",
    "    lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.linear.set_weights_stdev(0.02)\n",
    "\n",
    "    output = lib.ops.conv2d.Conv2D(\"Discriminator.1\", 3, dim, 5, output, stride=2)\n",
    "    print('Discriminator output 1: ', output)\n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 1 nonlinear: ', output)\n",
    "    print('#######################')\n",
    "######################\n",
    "    output = lib.ops.conv2d.Conv2D(\"Discriminator.2\", dim, 2 * dim, 5, output, stride=2)\n",
    "    print('Discriminator output 2: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Discriminator.BN2\", [0, 2, 3], output)\n",
    "        print('Discriminator output 2 bn: ', output)\n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 2 nonlinear: ', output)\n",
    "    print('#######################')\n",
    "######################\n",
    "    output = lib.ops.conv2d.Conv2D(\n",
    "        \"Discriminator.3\", 2 * dim, 4 * dim, 5, output, stride=2\n",
    "    )\n",
    "    print('Discriminator output 3: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Discriminator.BN3\", [0, 2, 3], output)\n",
    "        print('Discriminator output 3 bn: ', output)\n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 3 nonlinear: ', output)\n",
    "    print('#######################')\n",
    "######################\n",
    "    output = lib.ops.conv2d.Conv2D(\n",
    "        \"Discriminator.4\", 4 * dim, 8 * dim, 5, output, stride=2\n",
    "    )\n",
    "    print('Discriminator output 4: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Discriminator.BN4\", [0, 2, 3], output)\n",
    "        print('Discriminator output 4 bn: ', output)\n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 4 nonlinear: ', output)\n",
    "    finalLayer = tf.reshape(output, [-1, 4 * 4 * 8 * dim])\n",
    "    print('Discriminator output final: ', output)\n",
    "    print('#######################')\n",
    "######################\n",
    "    sourceOutput = lib.ops.linear.Linear(\n",
    "        \"Discriminator.sourceOutput\", 4 * 4 * 8 * dim, 1, finalLayer\n",
    "    )\n",
    "    print('Discriminator source output: ', output)\n",
    "    classOutput = lib.ops.linear.Linear(\n",
    "        \"Discriminator.classOutput\", 4 * 4 * 8 * dim, numClasses, finalLayer\n",
    "    )\n",
    "    print('Discriminator class output: ', output)\n",
    "    print('#######################')\n",
    "    lib.ops.conv2d.unset_weights_stdev()\n",
    "    lib.ops.deconv2d.unset_weights_stdev()\n",
    "    lib.ops.linear.unset_weights_stdev()\n",
    "    print('#######################')\n",
    "    return (tf.reshape(sourceOutput, [-1]), tf.reshape(classOutput, [-1, numClasses]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b6ff131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genRandomLabels(n_samples, numClasses, condition=None):\n",
    "    labels = np.zeros([BATCH_SIZE, CLASSES], dtype=np.float32)\n",
    "    for i in range(n_samples):\n",
    "        if condition is not None:\n",
    "            labelNum = condition\n",
    "        else:\n",
    "            labelNum = randint(0, numClasses - 1)\n",
    "        labels[i, labelNum] = 1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ee33186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Generator, Discriminator = GeneratorAndDiscriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7701268c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/gpu:0']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "28dcd409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started ...\n",
      "real_data:  Tensor(\"Reshape_51:0\", shape=(84, 12288), dtype=float32, device=/device:GPU:0)\n",
      "real_labels:  Tensor(\"Reshape_52:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n",
      "generated_labels:  Tensor(\"Reshape_53:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n",
      "sample_labels:  Tensor(\"Reshape_54:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n",
      "Generator output 1:  Tensor(\"Generator.Input_3/BiasAdd:0\", shape=(84, 16384), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 1 reshape:  Tensor(\"Reshape_55:0\", shape=(84, 1024, 4, 4), dtype=float32, device=/device:GPU:0) (84, 1024, 4, 4)\n",
      "Generator output 1 bn:  Tensor(\"FusedBatchNormV3_9:0\", shape=(84, 1024, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 1 final:  Tensor(\"mul_27:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Structure 1:  512 Tensor(\"strided_slice_69:0\", shape=(84, 256, 4, 4), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_70:0\", shape=(84, 256, 4, 4), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_71:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_72:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Generator output 2:  Tensor(\"Generator.2_2/NHWC_to_NCHW:0\", shape=(84, 512, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 2 bn:  Tensor(\"FusedBatchNormV3_10:0\", shape=(84, 512, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 2 final:  Tensor(\"mul_28:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Structure 2:  256 Tensor(\"strided_slice_77:0\", shape=(84, 128, 8, 8), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_78:0\", shape=(84, 128, 8, 8), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_79:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_80:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Generator output 3:  Tensor(\"Generator.3_2/NHWC_to_NCHW:0\", shape=(84, 256, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 3 bn:  Tensor(\"FusedBatchNormV3_11:0\", shape=(84, 256, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 3 final:  Tensor(\"mul_29:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Structure 3:  128 Tensor(\"strided_slice_85:0\", shape=(84, 64, 16, 16), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_86:0\", shape=(84, 64, 16, 16), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_87:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_88:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Generator output 4:  Tensor(\"Generator.4_2/NHWC_to_NCHW:0\", shape=(84, 128, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 4 bn:  Tensor(\"FusedBatchNormV3_12:0\", shape=(84, 128, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 4 final:  Tensor(\"mul_30:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Structure 4:  64 Tensor(\"strided_slice_93:0\", shape=(84, 32, 32, 32), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_94:0\", shape=(84, 32, 32, 32), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_95:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_96:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Generator output 6:  Tensor(\"Generator.5_2/NHWC_to_NCHW:0\", shape=(84, 3, 64, 64), dtype=float32, device=/device:GPU:0)\n",
      "Generator output final:  Tensor(\"Tanh_14:0\", shape=(84, 3, 64, 64), dtype=float32, device=/device:GPU:0)\n",
      "fake_data:  Tensor(\"Reshape_60:0\", shape=(84, 12288), dtype=float32, device=/device:GPU:0)\n",
      "fake_labels:  Tensor(\"Cast_8:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 1:  Tensor(\"Discriminator.1_3/BiasAdd:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 1 nonlinear:  Tensor(\"Maximum_12:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 2:  Tensor(\"Discriminator.2_3/BiasAdd:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 bn:  Tensor(\"batchnorm_9/add_1:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 nonlinear:  Tensor(\"Maximum_13:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 3:  Tensor(\"Discriminator.3_3/BiasAdd:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 3 bn:  Tensor(\"batchnorm_10/add_1:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 3 nonlinear:  Tensor(\"Maximum_14:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 4:  Tensor(\"Discriminator.4_3/BiasAdd:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 4 bn:  Tensor(\"batchnorm_11/add_1:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 4 nonlinear:  Tensor(\"Maximum_15:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output final:  Tensor(\"Maximum_15:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator source output:  Tensor(\"Maximum_15:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator class output:  Tensor(\"Maximum_15:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "#######################\n",
      "disc fake:  Tensor(\"Reshape_69:0\", shape=(84,), dtype=float32, device=/device:GPU:0) Tensor(\"Reshape_70:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 1:  Tensor(\"Discriminator.1_4/BiasAdd:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 1 nonlinear:  Tensor(\"Maximum_16:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 2:  Tensor(\"Discriminator.2_4/BiasAdd:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 bn:  Tensor(\"batchnorm_12/add_1:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 nonlinear:  Tensor(\"Maximum_17:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 3:  Tensor(\"Discriminator.3_4/BiasAdd:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 3 bn:  Tensor(\"batchnorm_13/add_1:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 3 nonlinear:  Tensor(\"Maximum_18:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 4:  Tensor(\"Discriminator.4_4/BiasAdd:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 4 bn:  Tensor(\"batchnorm_14/add_1:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 4 nonlinear:  Tensor(\"Maximum_19:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output final:  Tensor(\"Maximum_19:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator source output:  Tensor(\"Maximum_19:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator class output:  Tensor(\"Maximum_19:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "#######################\n",
      "disc real:  Tensor(\"Reshape_79:0\", shape=(84,), dtype=float32, device=/device:GPU:0) Tensor(\"Reshape_80:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "prediction 1:  Tensor(\"ArgMax_4:0\", shape=(84,), dtype=int64, device=/device:GPU:0) Tensor(\"Reshape_70:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "correct 1:  Tensor(\"ArgMax_5:0\", shape=(84,), dtype=int64, device=/device:GPU:0) Tensor(\"Cast_8:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "equality 1:  Tensor(\"Equal_2:0\", shape=(84,), dtype=bool, device=/device:GPU:0)\n",
      "accuracy 1:  Tensor(\"Mean_11:0\", shape=(), dtype=float32, device=/device:GPU:0)\n",
      "prediction 2:  Tensor(\"ArgMax_6:0\", shape=(84,), dtype=int64, device=/device:GPU:0)\n",
      "disc real class:  Tensor(\"Reshape_80:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "correct 2:  Tensor(\"ArgMax_7:0\", shape=(84,), dtype=int64, device=/device:GPU:0) Tensor(\"Reshape_52:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n",
      "equality 2:  Tensor(\"Equal_3:0\", shape=(84,), dtype=bool, device=/device:GPU:0)\n",
      "Discriminator output 1:  Tensor(\"Discriminator.1_5/BiasAdd:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 1 nonlinear:  Tensor(\"Maximum_20:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 2:  Tensor(\"Discriminator.2_5/BiasAdd:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 bn:  Tensor(\"batchnorm_15/add_1:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 nonlinear:  Tensor(\"Maximum_21:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 3:  Tensor(\"Discriminator.3_5/BiasAdd:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 3 bn:  Tensor(\"batchnorm_16/add_1:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 3 nonlinear:  Tensor(\"Maximum_22:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 4:  Tensor(\"Discriminator.4_5/BiasAdd:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 4 bn:  Tensor(\"batchnorm_17/add_1:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 4 nonlinear:  Tensor(\"Maximum_23:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output final:  Tensor(\"Maximum_23:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator source output:  Tensor(\"Maximum_23:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator class output:  Tensor(\"Maximum_23:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "#######################\n",
      "Generator output 1:  Tensor(\"Generator.Input_4/BiasAdd:0\", shape=(84, 16384), dtype=float32)\n",
      "Generator output 1 reshape:  Tensor(\"Reshape_91:0\", shape=(84, 1024, 4, 4), dtype=float32) (84, 1024, 4, 4)\n",
      "Generator output 1 bn:  Tensor(\"FusedBatchNormV3_13:0\", shape=(84, 1024, 4, 4), dtype=float32)\n",
      "Generator output 1 final:  Tensor(\"mul_47:0\", shape=(84, 512, 4, 4), dtype=float32)\n",
      "Structure 1:  512 Tensor(\"strided_slice_102:0\", shape=(84, 256, 4, 4), dtype=float32) Tensor(\"strided_slice_103:0\", shape=(84, 256, 4, 4), dtype=float32) Tensor(\"strided_slice_104:0\", shape=(84, 512, 4, 4), dtype=float32) Tensor(\"strided_slice_105:0\", shape=(84, 512, 4, 4), dtype=float32)\n",
      "#######################\n",
      "Generator output 2:  Tensor(\"Generator.2_3/NHWC_to_NCHW:0\", shape=(84, 512, 8, 8), dtype=float32)\n",
      "Generator output 2 bn:  Tensor(\"FusedBatchNormV3_14:0\", shape=(84, 512, 8, 8), dtype=float32)\n",
      "Generator output 2 final:  Tensor(\"mul_48:0\", shape=(84, 256, 8, 8), dtype=float32)\n",
      "Structure 2:  256 Tensor(\"strided_slice_110:0\", shape=(84, 128, 8, 8), dtype=float32) Tensor(\"strided_slice_111:0\", shape=(84, 128, 8, 8), dtype=float32) Tensor(\"strided_slice_112:0\", shape=(84, 256, 8, 8), dtype=float32) Tensor(\"strided_slice_113:0\", shape=(84, 256, 8, 8), dtype=float32)\n",
      "#######################\n",
      "Generator output 3:  Tensor(\"Generator.3_3/NHWC_to_NCHW:0\", shape=(84, 256, 16, 16), dtype=float32)\n",
      "Generator output 3 bn:  Tensor(\"FusedBatchNormV3_15:0\", shape=(84, 256, 16, 16), dtype=float32)\n",
      "Generator output 3 final:  Tensor(\"mul_49:0\", shape=(84, 128, 16, 16), dtype=float32)\n",
      "Structure 3:  128 Tensor(\"strided_slice_118:0\", shape=(84, 64, 16, 16), dtype=float32) Tensor(\"strided_slice_119:0\", shape=(84, 64, 16, 16), dtype=float32) Tensor(\"strided_slice_120:0\", shape=(84, 128, 16, 16), dtype=float32) Tensor(\"strided_slice_121:0\", shape=(84, 128, 16, 16), dtype=float32)\n",
      "#######################\n",
      "Generator output 4:  Tensor(\"Generator.4_3/NHWC_to_NCHW:0\", shape=(84, 128, 32, 32), dtype=float32)\n",
      "Generator output 4 bn:  Tensor(\"FusedBatchNormV3_16:0\", shape=(84, 128, 32, 32), dtype=float32)\n",
      "Generator output 4 final:  Tensor(\"mul_50:0\", shape=(84, 64, 32, 32), dtype=float32)\n",
      "Structure 4:  64 Tensor(\"strided_slice_126:0\", shape=(84, 32, 32, 32), dtype=float32) Tensor(\"strided_slice_127:0\", shape=(84, 32, 32, 32), dtype=float32) Tensor(\"strided_slice_128:0\", shape=(84, 64, 32, 32), dtype=float32) Tensor(\"strided_slice_129:0\", shape=(84, 64, 32, 32), dtype=float32)\n",
      "#######################\n",
      "Generator output 6:  Tensor(\"Generator.5_3/NHWC_to_NCHW:0\", shape=(84, 3, 64, 64), dtype=float32)\n",
      "Generator output final:  Tensor(\"Tanh_19:0\", shape=(84, 3, 64, 64), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-6bf3145cd853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0miterp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPREITERATIONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         _, accuracy = session.run(\n\u001b[1;32m    200\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mdisc_train_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealAccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-b06ebe247ae9>\u001b[0m in \u001b[0;36mget_epoch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m                         \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_img_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyleLabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2982\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2984\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2986\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as session:\n",
    "    print('started ...')\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    all_real_data_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, 3, DIM, DIM])\n",
    "    all_real_label_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, CLASSES])\n",
    "\n",
    "    generated_labels_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, CLASSES])\n",
    "    sample_labels_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, CLASSES])\n",
    "\n",
    "    split_real_data_conv = tf.split(all_real_data_conv, len(DEVICES))\n",
    "    split_real_label_conv = tf.split(all_real_label_conv, len(DEVICES))\n",
    "    split_generated_labels_conv = tf.split(generated_labels_conv, len(DEVICES))\n",
    "    split_sample_labels_conv = tf.split(sample_labels_conv, len(DEVICES))\n",
    "\n",
    "    gen_costs, disc_costs = [], []\n",
    "\n",
    "    for device_index, (device, real_data_conv, real_label_conv) in enumerate(\n",
    "        zip(DEVICES, split_real_data_conv, split_real_label_conv)\n",
    "    ):\n",
    "        with tf.device(device):\n",
    "\n",
    "            real_data = tf.reshape(\n",
    "                2 * ((tf.cast(real_data_conv, tf.float32) / 255.0) - 0.5),\n",
    "                [BATCH_SIZE // len(DEVICES), OUTPUT_DIM],\n",
    "            )\n",
    "            print('real_data: ', real_data)\n",
    "            real_labels = tf.reshape(\n",
    "                real_label_conv, [BATCH_SIZE // len(DEVICES), CLASSES]\n",
    "            )\n",
    "            print('real_labels: ', real_labels)\n",
    "            generated_labels = tf.reshape(\n",
    "                split_generated_labels_conv, [BATCH_SIZE // len(DEVICES), CLASSES]\n",
    "            )\n",
    "            print('generated_labels: ', generated_labels)\n",
    "            sample_labels = tf.reshape(\n",
    "                split_sample_labels_conv, [BATCH_SIZE // len(DEVICES), CLASSES]\n",
    "            )\n",
    "            print('sample_labels: ', sample_labels)\n",
    "            fake_data, fake_labels = Generator(\n",
    "                BATCH_SIZE // len(DEVICES), CLASSES, generated_labels\n",
    "            )\n",
    "#             print(real_data,real_labels,generated_labels,sample_labels,fake_data, fake_labels)\n",
    "            print('fake_data: ', fake_data)\n",
    "            print('fake_labels: ', fake_labels)\n",
    "            # set up discrimnator results\n",
    "\n",
    "            disc_fake, disc_fake_class = Discriminator(fake_data, CLASSES)\n",
    "            print('disc fake: ', disc_fake, disc_fake_class)\n",
    "            disc_real, disc_real_class = Discriminator(real_data, CLASSES)\n",
    "            print('disc real: ', disc_real, disc_real_class)\n",
    "            prediction = tf.argmax(disc_fake_class, 1)\n",
    "            print('prediction 1: ', prediction, disc_fake_class)\n",
    "            correct_answer = tf.argmax(fake_labels, 1)\n",
    "            print('correct 1: ', correct_answer, fake_labels)\n",
    "            equality = tf.equal(prediction, correct_answer)\n",
    "            print('equality 1: ', equality)\n",
    "            genAccuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "            print('accuracy 1: ', genAccuracy)\n",
    "            \n",
    "            prediction = tf.argmax(disc_real_class, 1)\n",
    "            print('prediction 2: ', prediction)\n",
    "            print('disc real class: ', disc_real_class)\n",
    "            correct_answer = tf.argmax(real_labels, 1)\n",
    "            print('correct 2: ', correct_answer, real_labels)\n",
    "#             equality = tf.equal(correct_answer, prediction)\n",
    "            equality = tf.equal(prediction, correct_answer)\n",
    "            print('equality 2: ', equality)\n",
    "            realAccuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "\n",
    "            gen_cost = -tf.reduce_mean(disc_fake)\n",
    "            disc_cost = tf.reduce_mean(disc_fake) - tf.reduce_mean(disc_real)\n",
    "\n",
    "            gen_cost_test = -tf.reduce_mean(disc_fake)\n",
    "            disc_cost_test = tf.reduce_mean(disc_fake) - tf.reduce_mean(disc_real)\n",
    "\n",
    "            generated_class_cost = tf.reduce_mean(\n",
    "                tf.nn.softmax_cross_entropy_with_logits(\n",
    "                    logits=disc_fake_class, labels=fake_labels\n",
    "                )\n",
    "            )\n",
    "\n",
    "            real_class_cost = tf.reduce_mean(\n",
    "                tf.nn.softmax_cross_entropy_with_logits(\n",
    "                    logits=disc_real_class, labels=real_labels\n",
    "                )\n",
    "            )\n",
    "            gen_cost += generated_class_cost\n",
    "            disc_cost += real_class_cost\n",
    "\n",
    "            alpha = tf.random_uniform(\n",
    "                shape=[BATCH_SIZE // len(DEVICES), 1], minval=0.0, maxval=1.0\n",
    "            )\n",
    "            differences = fake_data - real_data\n",
    "            interpolates = real_data + (alpha * differences)\n",
    "            gradients = tf.gradients(\n",
    "                Discriminator(interpolates, CLASSES)[0], [interpolates]\n",
    "            )[0]\n",
    "            slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "            gradient_penalty = tf.reduce_mean((slopes - 1.0) ** 2)\n",
    "            disc_cost += LAMBDA * gradient_penalty\n",
    "\n",
    "            real_class_cost_gradient = real_class_cost * 50 + LAMBDA * gradient_penalty\n",
    "\n",
    "            gen_costs.append(gen_cost)\n",
    "            disc_costs.append(disc_cost)\n",
    "\n",
    "    gen_cost = tf.add_n(gen_costs) / len(DEVICES)\n",
    "    disc_cost = tf.add_n(disc_costs) / len(DEVICES)\n",
    "\n",
    "    gen_train_op = tf.train.AdamOptimizer(\n",
    "        learning_rate=1e-4, beta1=0.5, beta2=0.9\n",
    "    ).minimize(\n",
    "        gen_cost,\n",
    "        var_list=lib.params_with_name(\"Generator\"),\n",
    "        colocate_gradients_with_ops=True,\n",
    "    )\n",
    "    disc_train_op = tf.train.AdamOptimizer(\n",
    "        learning_rate=1e-4, beta1=0.5, beta2=0.9\n",
    "    ).minimize(\n",
    "        disc_cost,\n",
    "        var_list=lib.params_with_name(\"Discriminator.\"),\n",
    "        colocate_gradients_with_ops=True,\n",
    "    )\n",
    "    class_train_op = tf.train.AdamOptimizer(\n",
    "        learning_rate=1e-4, beta1=0.5, beta2=0.9\n",
    "    ).minimize(\n",
    "        real_class_cost_gradient,\n",
    "        var_list=lib.params_with_name(\"Discriminator.\"),\n",
    "        colocate_gradients_with_ops=True,\n",
    "    )\n",
    "    # For generating samples\n",
    "\n",
    "    fixed_noise = tf.constant(\n",
    "        np.random.normal(size=(BATCH_SIZE, 128)).astype(\"float32\")\n",
    "    )\n",
    "    all_fixed_noise_samples = []\n",
    "    for device_index, device in enumerate(DEVICES):\n",
    "        n_samples = BATCH_SIZE // len(DEVICES)\n",
    "        all_fixed_noise_samples.append(\n",
    "            Generator(\n",
    "                n_samples,\n",
    "                CLASSES,\n",
    "                sample_labels,\n",
    "                noise=fixed_noise[\n",
    "                    device_index * n_samples : (device_index + 1) * n_samples\n",
    "                ],\n",
    "            )[0]\n",
    "        )\n",
    "        if tf.__version__.startswith(\"1.\"):\n",
    "            all_fixed_noise_samples = tf.concat(all_fixed_noise_samples, axis=0)\n",
    "        else:\n",
    "            all_fixed_noise_samples = tf.concat(0, all_fixed_noise_samples)\n",
    "\n",
    "    def generate_image(iteration):\n",
    "        # this might be where we add the conditionality\n",
    "        for i in range(CLASSES):\n",
    "            curLabel = genRandomLabels(BATCH_SIZE, CLASSES, condition=i)\n",
    "            samples = session.run(\n",
    "                all_fixed_noise_samples, feed_dict={sample_labels: curLabel}\n",
    "            )\n",
    "            samples = ((samples + 1.0) * (255.99 / 2)).astype(\"int32\")\n",
    "            lib.save_images.save_images(\n",
    "                samples.reshape((BATCH_SIZE, 3, DIM, DIM)),\n",
    "                \"generated/samples_{}_{}.png\".format(str(i), iteration),\n",
    "            )\n",
    "\n",
    "    # Dataset iterator\n",
    "#     train_gen, dev_gen = lib.wikiart_genre.load(BATCH_SIZE)\n",
    "    train_gen, dev_gen = load(BATCH_SIZE)\n",
    "\n",
    "    def softmax_cross_entropy(logit, y):\n",
    "        return -tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=y)\n",
    "        )\n",
    "\n",
    "    def inf_train_gen():\n",
    "        while True:\n",
    "            for (images, labels) in train_gen():\n",
    "                yield images, labels\n",
    "\n",
    "    _sample_labels = genRandomLabels(BATCH_SIZE, CLASSES)\n",
    "    # Save a batch of ground-truth samples\n",
    "    _x, _y = next(train_gen())\n",
    "    _x_r = session.run(real_data, feed_dict={all_real_data_conv: _x})\n",
    "    _x_r = ((_x_r + 1.0) * (255.99 / 2)).astype(\"int32\")\n",
    "    lib.save_images.save_images(\n",
    "        _x_r.reshape((BATCH_SIZE, 3, DIM, DIM)), \"generated/samples_groundtruth.png\"\n",
    "    )\n",
    "\n",
    "    session.run(\n",
    "        tf.initialize_all_variables(),\n",
    "        feed_dict={generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES)},\n",
    "    )\n",
    "    gen = train_gen()\n",
    "\n",
    "    for iterp in range(PREITERATIONS):\n",
    "        _data, _labels = next(gen)\n",
    "        _, accuracy = session.run(\n",
    "            [disc_train_op, realAccuracy],\n",
    "            feed_dict={\n",
    "                all_real_data_conv: _data,\n",
    "                all_real_label_conv: _labels,\n",
    "                generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES),\n",
    "            },\n",
    "        )\n",
    "        if iterp % 100 == 99:\n",
    "            print(\"pretraining accuracy: \" + str(accuracy))\n",
    "\n",
    "    for iteration in range(ITERS):\n",
    "        start_time = time.time()\n",
    "        # Train generator\n",
    "        if iteration > 0:\n",
    "            _ = session.run(\n",
    "                gen_train_op,\n",
    "                feed_dict={generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES)},\n",
    "            )\n",
    "        # Train critic\n",
    "        disc_iters = CRITIC_ITERS\n",
    "        for i in range(disc_iters):\n",
    "            _data, _labels = next(gen)\n",
    "            (\n",
    "                _disc_cost,\n",
    "                _disc_cost_test,\n",
    "                class_cost_test,\n",
    "                gen_class_cost,\n",
    "                _gen_cost_test,\n",
    "                _genAccuracy,\n",
    "                _realAccuracy,\n",
    "                _,\n",
    "            ) = session.run(\n",
    "                [\n",
    "                    disc_cost,\n",
    "                    disc_cost_test,\n",
    "                    real_class_cost,\n",
    "                    generated_class_cost,\n",
    "                    gen_cost_test,\n",
    "                    genAccuracy,\n",
    "                    realAccuracy,\n",
    "                    disc_train_op,\n",
    "                ],\n",
    "                feed_dict={\n",
    "                    all_real_data_conv: _data,\n",
    "                    all_real_label_conv: _labels,\n",
    "                    generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES),\n",
    "                },\n",
    "            )\n",
    "\n",
    "        lib.plot.plot(\"train disc cost\", _disc_cost)\n",
    "        lib.plot.plot(\"time\", time.time() - start_time)\n",
    "        lib.plot.plot(\"wgan train disc cost\", _disc_cost_test)\n",
    "        lib.plot.plot(\"train class cost\", class_cost_test)\n",
    "        lib.plot.plot(\"generated class cost\", gen_class_cost)\n",
    "        lib.plot.plot(\"gen cost cost\", _gen_cost_test)\n",
    "        lib.plot.plot(\"gen accuracy\", _genAccuracy)\n",
    "        lib.plot.plot(\"real accuracy\", _realAccuracy)\n",
    "\n",
    "        if (iteration % 100 == 99 and iteration < 1000) or iteration % 1000 == 999:\n",
    "            t = time.time()\n",
    "            dev_disc_costs = []\n",
    "            images, labels = next(dev_gen())\n",
    "            (\n",
    "                _dev_disc_cost,\n",
    "                _dev_disc_cost_test,\n",
    "                _class_cost_test,\n",
    "                _gen_class_cost,\n",
    "                _dev_gen_cost_test,\n",
    "                _dev_genAccuracy,\n",
    "                _dev_realAccuracy,\n",
    "            ) = session.run(\n",
    "                [\n",
    "                    disc_cost,\n",
    "                    disc_cost_test,\n",
    "                    real_class_cost,\n",
    "                    generated_class_cost,\n",
    "                    gen_cost_test,\n",
    "                    genAccuracy,\n",
    "                    realAccuracy,\n",
    "                ],\n",
    "                feed_dict={\n",
    "                    all_real_data_conv: images,\n",
    "                    all_real_label_conv: labels,\n",
    "                    generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES),\n",
    "                },\n",
    "            )\n",
    "            dev_disc_costs.append(_dev_disc_cost)\n",
    "            lib.plot.plot(\"dev disc cost\", np.mean(dev_disc_costs))\n",
    "            lib.plot.plot(\"wgan dev disc cost\", _dev_disc_cost_test)\n",
    "            lib.plot.plot(\"dev class cost\", _class_cost_test)\n",
    "            lib.plot.plot(\"dev generated class cost\", _gen_class_cost)\n",
    "            lib.plot.plot(\"dev gen  cost\", _dev_gen_cost_test)\n",
    "            lib.plot.plot(\"dev gen accuracy\", _dev_genAccuracy)\n",
    "            lib.plot.plot(\"dev real accuracy\", _dev_realAccuracy)\n",
    "\n",
    "        if iteration % 100 == 999:\n",
    "            generate_image(iteration)\n",
    "            # Can add generate_good_images method in here if desired\n",
    "\n",
    "        if (iteration < 10) or (iteration % 100 == 99):\n",
    "            lib.plot.flush()\n",
    "\n",
    "        lib.plot.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5f47b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
