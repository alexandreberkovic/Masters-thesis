{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "225de497",
   "metadata": {},
   "source": [
    "# Deep Convolutional Neural Network for Art Classification with PyTorch\n",
    "# Part 3: pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb824b6",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ccb3e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import tarfile\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import random_split\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pathlib\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36be81a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name='CNN_classifier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95fafd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/Masters-thesis/Pre-processing'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67a04f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_str = Path('/home/ec2-user/SageMaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0025d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(path_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "919e29f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models',\n",
       " 'Connect to s3.ipynb',\n",
       " '.sparkmagic',\n",
       " 'Data split.ipynb',\n",
       " 'Pre-processing pipeline.ipynb',\n",
       " 'CNNs.ipynb',\n",
       " 'wikiart_post',\n",
       " 'wikiart_pre',\n",
       " 'Resnet.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " 'Masters-thesis',\n",
       " 'lost+found',\n",
       " 'wikiart_binary',\n",
       " 'Pre-trained cnn.ipynb']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "27a5f384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory of image folders per mouvement\n",
    "img_folders = Path(path_str+'/'+'Dataset/wikiart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2819c7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove DS_Store file\n",
    "folders = list(os.listdir(img_folders))\n",
    "folders.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a62447e",
   "metadata": {},
   "source": [
    "## Modify the CSV file after modification of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "018e2189",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_train = pd.read_csv(os.path.join(path_str,'Dataset/wikiart_csv/style_train.csv'), names = ['Path','Style'])\n",
    "style_val = pd.read_csv(os.path.join(path_str,'Dataset/wikiart_csv/style_val.csv'), names = ['Path','Style'])\n",
    "\n",
    "artist_train = pd.read_csv(os.path.join(path_str,'Dataset/wikiart_csv/artist_train.csv'), names = ['Path','Artist'])\n",
    "artist_val = pd.read_csv(os.path.join(path_str,'Dataset/wikiart_csv/artist_val.csv'), names = ['Path','Artist'])\n",
    "        \n",
    "genre_train = pd.read_csv(os.path.join(path_str,'Dataset/wikiart_csv/genre_train.csv'), names = ['Path','Genre'])\n",
    "genre_val = pd.read_csv(os.path.join(path_str,'Dataset/wikiart_csv/genre_val.csv'), names = ['Path','Genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "44479007",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [style_train,style_val,artist_train,artist_val,genre_train,genre_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "4a846f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_path(df):\n",
    "    df['Path'] = df['Path'].replace({'Analytical_Cubism': 'Cubism'}, regex=True)\n",
    "    df['Path'] = df['Path'].replace({'Synthetic_Cubism': 'Cubism'}, regex=True)\n",
    "    df['Path'] = df['Path'].replace({'Action_painting': 'Abstract_Expressionism'}, regex=True)\n",
    "    df['Path'] = df['Path'].replace({'New_Realism': 'Contemporary_realism'}, regex=True)\n",
    "    df['Path'] = df['Path'].replace({'Color_Field_Painting': 'Minimalism'}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1762fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(datasets)):\n",
    "    replace_path(datasets[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "4699d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_num(df):\n",
    "    df['Style'] = df['Style'].replace({2:7}, regex=True)\n",
    "    df['Style'] = df['Style'].replace({5:7}, regex=True)\n",
    "    df['Style'] = df['Style'].replace({1:0}, regex=True)\n",
    "    df['Style'] = df['Style'].replace({16:6}, regex=True)\n",
    "    df['Style'] = df['Style'].replace({5:14}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "085f6c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_num(style_train)\n",
    "replace_num(style_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "2a81b7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_train.to_csv(os.path.join(path_str,'Dataset/wikiart_csv/style_train.csv'))\n",
    "style_val.to_csv(os.path.join(path_str,'Dataset/wikiart_csv/style_val.csv'))\n",
    "\n",
    "artist_train.to_csv(os.path.join(path_str,'Dataset/wikiart_csv/artist_train.csv'))\n",
    "artist_val.to_csv(os.path.join(path_str,'Dataset/wikiart_csv/artist_val.csv'))\n",
    "        \n",
    "genre_train.to_csv(os.path.join(path_str,'Dataset/wikiart_csv/genre_train.csv'))\n",
    "genre_val.to_csv(os.path.join(path_str,'Dataset/wikiart_csv/genre_val.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eea768",
   "metadata": {},
   "source": [
    "## Create a subset of the dataset to play with during the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "43c2441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset(path):\n",
    "    for i in range(len(folders)):\n",
    "        dirpath = os.path.join(path,folders[i])\n",
    "        directory_length = len(list(os.listdir(dirpath)))\n",
    "        if directory_length < 2500:\n",
    "            subset_length = 250\n",
    "        elif directory_length > 12500:\n",
    "            subset_length = 1250\n",
    "        else:\n",
    "            subset_length = int(0.1*len(list(os.listdir(dirpath))))\n",
    "        filenames = random.sample(os.listdir(dirpath),subset_length)\n",
    "        print('{} has {} images'.format(folders[i], subset_length))\n",
    "#         print('Mouvement' + folders[i] \"has\" + str(directory_length) + 'images') \n",
    "        \n",
    "        destDirectory = os.path.join(path_str,'Dataset/Dataset_subset/',folders[i])\n",
    "        if not os.path.exists(destDirectory):\n",
    "            os.makedirs(destDirectory)\n",
    "            \n",
    "        else:\n",
    "            for f in os.listdir(destDirectory):\n",
    "                os.remove(os.path.join(destDirectory, f))\n",
    "       \n",
    "        for fname in filenames:\n",
    "            srcpath = os.path.join(dirpath, fname)\n",
    "            shutil.copy(srcpath, destDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "25746c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early_Renaissance has 250 images\n",
      "Mannerism_Late_Renaissance has 250 images\n",
      "Expressionism has 673 images\n",
      "Contemporary_Realism has 250 images\n",
      "Fauvism has 250 images\n",
      "Northern_Renaissance has 255 images\n",
      "Rococo has 250 images\n",
      "Ukiyo_e has 250 images\n",
      "Pop_Art has 250 images\n",
      "High_Renaissance has 250 images\n",
      "Minimalism has 291 images\n",
      "Art_Nouveau_Modern has 433 images\n",
      "Symbolism has 452 images\n",
      "Realism has 1073 images\n",
      "Romanticism has 701 images\n",
      "Cubism has 256 images\n",
      "Impressionism has 1250 images\n",
      "Baroque has 424 images\n",
      "Post_Impressionism has 645 images\n",
      "Abstract_Expressionism has 287 images\n",
      "Pointillism has 250 images\n",
      "Naive_Art_Primitivism has 250 images\n"
     ]
    }
   ],
   "source": [
    "subset(img_folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b429a3cc",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03df4a3",
   "metadata": {},
   "source": [
    "### Image resizing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "13bf289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory of image folders per mouvement\n",
    "subset_folders = os.path.join(path_str, 'Dataset/Dataset_subset')\n",
    "# Path(path_str+'/'+'Dataset/Dataset_subset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "eb689e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Early_Renaissance',\n",
       " 'Mannerism_Late_Renaissance',\n",
       " 'Expressionism',\n",
       " 'Contemporary_Realism',\n",
       " 'Fauvism',\n",
       " 'Northern_Renaissance',\n",
       " 'Rococo',\n",
       " 'Ukiyo_e',\n",
       " 'Pop_Art',\n",
       " 'High_Renaissance',\n",
       " 'Minimalism',\n",
       " 'Art_Nouveau_Modern',\n",
       " 'Symbolism',\n",
       " 'Realism',\n",
       " 'Romanticism',\n",
       " 'Cubism',\n",
       " 'Impressionism',\n",
       " 'Baroque',\n",
       " 'Post_Impressionism',\n",
       " 'Abstract_Expressionism',\n",
       " 'Pointillism',\n",
       " 'Naive_Art_Primitivism']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(subset_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b624bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_upper(path,cnn_size):\n",
    "    '''\n",
    "    Resizes the images so that one side is 256 and the other is larger\n",
    "    Crops it so that the output is 256x256\n",
    "    '''\n",
    "    for i in range(len(folders)):\n",
    "        dirpath = os.path.join(path,folders[i])\n",
    "        \n",
    "        images = [file for file in os.listdir(dirpath) if file.endswith(('jpeg', 'png', 'jpg'))]\n",
    "        name = folders[i]\n",
    "        saving_dir = os.path.join(path_str,'Dataset/Resized_cropped',name)\n",
    "        \n",
    "        if not os.path.exists(saving_dir):\n",
    "            os.makedirs(saving_dir)\n",
    "            \n",
    "        else:\n",
    "            for f in os.listdir(saving_dir):\n",
    "                os.remove(os.path.join(saving_dir, f))\n",
    "\n",
    "        for image in images:\n",
    "            img = Image.open(Path(str(subset_folders)+'/'+name+'/'+image))\n",
    "\n",
    "            if img.size[0] >= img.size[1] and img.size[1] > cnn_size:\n",
    "\n",
    "                fixed_height = cnn_size\n",
    "                height_percent = (fixed_height / float(img.size[1]))\n",
    "                width_size = int((float(img.size[0]) * float(height_percent)))\n",
    "                img = img.resize((width_size, fixed_height), PIL.Image.NEAREST)\n",
    "                cropped = crop(img)\n",
    "                cropped.save(os.path.join(saving_dir,image), optimize=True, quality=100)\n",
    "\n",
    "            elif img.size[0] < img.size[1] and img.size[0] > cnn_size:\n",
    "                fixed_width = cnn_size\n",
    "                width_percent = (fixed_width / float(img.size[0]))\n",
    "                height_size = int((float(img.size[1]) * float(width_percent)))\n",
    "                img = img.resize((fixed_width, height_size), PIL.Image.NEAREST)\n",
    "                cropped = crop(img)\n",
    "                cropped.save(os.path.join(saving_dir,image), optimize=True, quality=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ae124217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_lower(path,cnn_size):\n",
    "    '''\n",
    "    Resizes the images so that one side is 256 and the other is smaller\n",
    "    Fills blank space with 0s so that the output is 256x256\n",
    "    ''' \n",
    "    for i in range(len(folders)):\n",
    "        dirpath = os.path.join(path,folders[i])\n",
    "        \n",
    "        images = [file for file in os.listdir(dirpath) if file.endswith(('jpeg', 'png', 'jpg'))]\n",
    "        name = folders[i]\n",
    "        saving_dir = os.path.join(path_str,'Dataset/Resized_blank',name)\n",
    "\n",
    "        if not os.path.exists(saving_dir):\n",
    "            os.makedirs(saving_dir)\n",
    "        \n",
    "        else:\n",
    "            for f in os.listdir(saving_dir):\n",
    "                os.remove(os.path.join(saving_dir, f))\n",
    "\n",
    "        for image in images:\n",
    "            img = Image.open(Path(str(subset_folders)+'/'+name+'/'+image))\n",
    "        \n",
    "            if img.size[1] >= img.size[0] and img.size[0] > cnn_size:\n",
    "\n",
    "                fixed_height = cnn_size\n",
    "                height_percent = (fixed_height / float(img.size[1]))\n",
    "                width_size = int((float(img.size[0]) * float(height_percent)))\n",
    "                img = img.resize((width_size, fixed_height), PIL.Image.NEAREST)\n",
    "                filled = fill(img,(0, 0, 0))\n",
    "                filled.save(os.path.join(saving_dir,image), optimize=True, quality=100)\n",
    "\n",
    "            elif img.size[1] < img.size[0] and img.size[1] > cnn_size:\n",
    "                fixed_width = cnn_size\n",
    "                width_percent = (fixed_width / float(img.size[0]))\n",
    "                height_size = int((float(img.size[1]) * float(width_percent)))\n",
    "                img = img.resize((fixed_width, height_size), PIL.Image.NEAREST)\n",
    "                filled = fill(img,(0, 0, 0))\n",
    "                filled.save(os.path.join(saving_dir,image), optimize=True, quality=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "59101888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_compress(path,cnn_size):\n",
    "    '''\n",
    "    Resizes the images by compressing them\n",
    "    Output is 256x256\n",
    "    ''' \n",
    "    for i in range(len(folders)):\n",
    "        dirpath = os.path.join(path,folders[i])\n",
    "        \n",
    "        images = [file for file in os.listdir(dirpath) if file.endswith(('jpeg', 'png', 'jpg'))]\n",
    "        name = folders[i]\n",
    "        saving_dir = os.path.join(path_str,'Dataset/Resized_compressed',name)\n",
    "\n",
    "        if not os.path.exists(saving_dir):\n",
    "            os.makedirs(saving_dir)\n",
    "            \n",
    "        else:\n",
    "            for f in os.listdir(saving_dir):\n",
    "                os.remove(os.path.join(saving_dir, f))\n",
    "\n",
    "        for image in images:\n",
    "            img = Image.open(Path(str(subset_folders)+'/'+name+'/'+image))\n",
    "\n",
    "            if img.size[0] > cnn_size and img.size[1] > cnn_size:\n",
    "                resized_image = img.resize((256,256))\n",
    "                resized_image.save(os.path.join(saving_dir,image), optimize=True, quality=100)\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98d0c58",
   "metadata": {},
   "source": [
    "### Helper functions used after resizing to uniform image dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7e50c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(im,size):\n",
    "    '''\n",
    "    Crops the image when one side is 256 and the other is bigger\n",
    "    Outputs a 256x256 centred image\n",
    "    '''\n",
    "    # Opens a image in RGB mode\n",
    "#     im = Image.open(r\"C:\\Users\\Admin\\Pictures\\network.png\")\n",
    " \n",
    "    # Setting the points for cropped image\n",
    "    width, height = im.size\n",
    "    if width == size:\n",
    "        left = 0\n",
    "        right = size\n",
    "        top = height//2 - size//2\n",
    "        bottom = height//2 + size//2\n",
    "\n",
    "    elif height == size:\n",
    "        left = width//2 - size\n",
    "        right = width//2 + size\n",
    "        top = 0\n",
    "        bottom = size\n",
    "        \n",
    "    # Cropped image of above dimension\n",
    "    # (It will not change original image)\n",
    "    im1 = im.crop((left, top, right, bottom))\n",
    "    return im1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "bd61471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill(pil_img, background_color):\n",
    "    '''\n",
    "    Fills the image with 0s when one side is 256 and the other is smaller\n",
    "    Outputs a 256x256 centred image\n",
    "    '''\n",
    "    width, height = pil_img.size\n",
    "    if width == height:\n",
    "        return pil_img\n",
    "    elif width > height:\n",
    "        result = Image.new(pil_img.mode, (width, width), background_color)\n",
    "        result.paste(pil_img, (0, (width - height) // 2))\n",
    "        return result\n",
    "    else:\n",
    "        result = Image.new(pil_img.mode, (height, height), background_color)\n",
    "        result.paste(pil_img, ((height - width) // 2, 0))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b19607",
   "metadata": {},
   "source": [
    "### Creating the usable dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7498bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize_upper(subset_folders,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9f6b78e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize_lower(subset_folders,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d835e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize_compress(subset_folders,256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p36",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
