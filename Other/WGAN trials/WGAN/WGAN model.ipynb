{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0b0df8e",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35078227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d557cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization parameters for pre-trained PyTorch models\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fb68303",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88b87075",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec1196ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory:  11.996954624\n",
      "Reserved memory:  0.42991616\n",
      "Allocated memory:  0.388125184\n"
     ]
    }
   ],
   "source": [
    "print(\"Total memory: \", t/10**9)\n",
    "print(\"Reserved memory: \", r/10**9)\n",
    "print(\"Allocated memory: \", a/10**9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df205664",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7537d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afb3480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(opt.latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.shape[0], *img_shape)\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc79a0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.shape[0], -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bea4eb8",
   "metadata": {},
   "source": [
    "# WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "000d3899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import sys\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# from models import *\n",
    "# from datasets import *\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91578c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"images\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c50c7da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--sample_interval'], dest='sample_interval', nargs=None, const=None, default=100, type=<class 'int'>, choices=None, help='interval betwen image samples', metavar=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=2000, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=2500, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"learning rate\") # was 0.00005\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--latent_dim\", type=int, default=100, help=\"dimensionality of the latent space\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=64, help=\"size of each image dimension\")\n",
    "parser.add_argument(\"--channels\", type=int, default=3, help=\"number of image channels\")\n",
    "parser.add_argument(\"--n_critic\", type=int, default=10, help=\"number of training steps for discriminator per iter\")\n",
    "parser.add_argument(\"--clip_value\", type=float, default=0.01, help=\"lower and upper clip value for disc. weights\")\n",
    "parser.add_argument(\"--sample_interval\", type=int, default=100, help=\"interval betwen image samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50aa694c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=2500, channels=3, clip_value=0.01, img_size=64, latent_dim=100, lr=0.0002, n_cpu=8, n_critic=10, n_epochs=2000, sample_interval=100)\n"
     ]
    }
   ],
   "source": [
    "opt = parser.parse_args(\"\")\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1570d375",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (opt.channels, opt.img_size, opt.img_size)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f280f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e013c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e9fc3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |  456080 KB |  514771 KB |   17996 MB |   17551 MB |\\n|       from large pool |  450560 KB |  507904 KB |   17329 MB |   16889 MB |\\n|       from small pool |    5520 KB |    9891 KB |     667 MB |     661 MB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |  456080 KB |  514771 KB |   17996 MB |   17551 MB |\\n|       from large pool |  450560 KB |  507904 KB |   17329 MB |   16889 MB |\\n|       from small pool |    5520 KB |    9891 KB |     667 MB |     661 MB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |  468992 KB |  522240 KB |  571392 KB |  102400 KB |\\n|       from large pool |  462848 KB |  512000 KB |  561152 KB |   98304 KB |\\n|       from small pool |    6144 KB |   10240 KB |   10240 KB |    4096 KB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |   12911 KB |  114646 KB |    8475 MB |    8462 MB |\\n|       from large pool |   12288 KB |  112448 KB |    7787 MB |    7775 MB |\\n|       from small pool |     623 KB |    4456 KB |     688 MB |     687 MB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     103    |     103    |    4652    |    4549    |\\n|       from large pool |      15    |      20    |    1303    |    1288    |\\n|       from small pool |      88    |      88    |    3349    |    3261    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     103    |     103    |    4652    |    4549    |\\n|       from large pool |      15    |      20    |    1303    |    1288    |\\n|       from small pool |      88    |      88    |    3349    |    3261    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      14    |      17    |      18    |       4    |\\n|       from large pool |      11    |      12    |      13    |       2    |\\n|       from small pool |       3    |       5    |       5    |       2    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       5    |      18    |    2223    |    2218    |\\n|       from large pool |       2    |       7    |     527    |     525    |\\n|       from small pool |       3    |      12    |    1696    |    1693    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29bb376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.RMSprop(generator.parameters(), lr=opt.lr)\n",
    "optimizer_D = torch.optim.RMSprop(discriminator.parameters(), lr=opt.lr)\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f00f437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('/home/ec2-user/SageMaker/genre-224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "586f66eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(opt.img_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "# image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'test']}\n",
    "image_datasets = datasets.ImageFolder(os.path.join(data_dir), data_transforms)\n",
    "# # Create training and validation dataloaders\n",
    "# dataloader = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=opt.batch_size, shuffle=True, num_workers=4) for x in ['train', 'test']}\n",
    "dataloader = torch.utils.data.DataLoader(image_datasets, batch_size=opt.batch_size, shuffle=True, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06eabd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 29954\n",
       "    Root location: /home/ec2-user/SageMaker/genre-224\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               RandomResizedCrop(size=(64, 64), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3b07de0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-37489454ecf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# path = Path('/home/ec2-user/SageMaker/portrait_landscape/1')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcorrupted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "# path = Path('/home/ec2-user/SageMaker/portrait_landscape/1')\n",
    "corrupted = []\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith('.jpg'):\n",
    "        try:\n",
    "            img = Image.open(os.path.join(path,filename)) # open the image file\n",
    "            img.verify() # verify that it is, in fact an image\n",
    "        except (IOError, SyntaxError) as e:\n",
    "#             pass\n",
    "            print('Bad file:', filename) # print out the names of corrupt files\n",
    "            corrupted.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7aa482f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images in corrupted:\n",
    "    os.remove(os.path.join(path,images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/2000] [Batch 0/12] [D loss: -0.096564] [G loss: 0.007673]\n",
      "[Epoch 0/2000] [Batch 10/12] [D loss: -123.987778] [G loss: -5.795136]\n",
      "[Epoch 1/2000] [Batch 0/12] [D loss: -126.127647] [G loss: -24.477129]\n",
      "[Epoch 1/2000] [Batch 10/12] [D loss: -165.509247] [G loss: -66.018913]\n",
      "[Epoch 2/2000] [Batch 0/12] [D loss: -117.189331] [G loss: -117.394600]\n",
      "[Epoch 2/2000] [Batch 10/12] [D loss: -100.796921] [G loss: -54.765972]\n",
      "[Epoch 3/2000] [Batch 0/12] [D loss: -96.833038] [G loss: -45.293076]\n",
      "[Epoch 3/2000] [Batch 10/12] [D loss: -136.978195] [G loss: 23.657171]\n",
      "[Epoch 4/2000] [Batch 0/12] [D loss: -140.652405] [G loss: 27.939419]\n",
      "[Epoch 4/2000] [Batch 10/12] [D loss: -167.352600] [G loss: 40.095245]\n",
      "[Epoch 5/2000] [Batch 0/12] [D loss: -168.273712] [G loss: 36.694534]\n",
      "[Epoch 5/2000] [Batch 10/12] [D loss: -202.544968] [G loss: 36.324276]\n",
      "[Epoch 6/2000] [Batch 0/12] [D loss: -195.846283] [G loss: 32.356129]\n",
      "[Epoch 6/2000] [Batch 10/12] [D loss: -208.237045] [G loss: 32.137833]\n",
      "[Epoch 7/2000] [Batch 0/12] [D loss: -196.401321] [G loss: 28.434475]\n",
      "[Epoch 7/2000] [Batch 10/12] [D loss: -206.964890] [G loss: 27.454571]\n",
      "[Epoch 8/2000] [Batch 0/12] [D loss: -198.404922] [G loss: 24.161757]\n",
      "[Epoch 8/2000] [Batch 10/12] [D loss: -214.451324] [G loss: 22.794497]\n",
      "[Epoch 9/2000] [Batch 0/12] [D loss: -196.832687] [G loss: 19.717106]\n",
      "[Epoch 9/2000] [Batch 10/12] [D loss: -208.383621] [G loss: 18.217390]\n",
      "[Epoch 10/2000] [Batch 0/12] [D loss: -190.190002] [G loss: 15.751378]\n",
      "[Epoch 10/2000] [Batch 10/12] [D loss: -200.774628] [G loss: 14.210662]\n",
      "[Epoch 11/2000] [Batch 0/12] [D loss: -188.169571] [G loss: 12.010928]\n",
      "[Epoch 11/2000] [Batch 10/12] [D loss: -197.932709] [G loss: 10.314752]\n",
      "[Epoch 12/2000] [Batch 0/12] [D loss: -197.245209] [G loss: 8.513298]\n",
      "[Epoch 12/2000] [Batch 10/12] [D loss: -193.852097] [G loss: 6.579979]\n",
      "[Epoch 13/2000] [Batch 0/12] [D loss: -188.696304] [G loss: 5.352207]\n",
      "[Epoch 13/2000] [Batch 10/12] [D loss: -189.981079] [G loss: 3.979895]\n",
      "[Epoch 14/2000] [Batch 0/12] [D loss: -193.047195] [G loss: 3.188305]\n",
      "[Epoch 14/2000] [Batch 10/12] [D loss: -187.590576] [G loss: 2.309286]\n",
      "[Epoch 15/2000] [Batch 0/12] [D loss: -204.685730] [G loss: 1.854735]\n",
      "[Epoch 15/2000] [Batch 10/12] [D loss: -201.793304] [G loss: 1.362495]\n",
      "[Epoch 16/2000] [Batch 0/12] [D loss: -187.695450] [G loss: 1.068809]\n",
      "[Epoch 16/2000] [Batch 10/12] [D loss: -193.857147] [G loss: 0.784654]\n",
      "[Epoch 17/2000] [Batch 0/12] [D loss: -190.053040] [G loss: 0.609187]\n",
      "[Epoch 17/2000] [Batch 10/12] [D loss: -195.818558] [G loss: 0.449115]\n",
      "[Epoch 18/2000] [Batch 0/12] [D loss: -187.260590] [G loss: 0.278321]\n",
      "[Epoch 18/2000] [Batch 10/12] [D loss: -195.785950] [G loss: 0.064765]\n",
      "[Epoch 19/2000] [Batch 0/12] [D loss: -195.607086] [G loss: -1.370734]\n",
      "[Epoch 19/2000] [Batch 10/12] [D loss: -179.755280] [G loss: -9.872859]\n",
      "[Epoch 20/2000] [Batch 0/12] [D loss: -161.732986] [G loss: -33.630650]\n",
      "[Epoch 20/2000] [Batch 10/12] [D loss: -139.661224] [G loss: -63.308743]\n",
      "[Epoch 21/2000] [Batch 0/12] [D loss: -96.884285] [G loss: -103.205650]\n",
      "[Epoch 21/2000] [Batch 10/12] [D loss: -62.583847] [G loss: -155.161224]\n",
      "[Epoch 22/2000] [Batch 0/12] [D loss: 35.121841] [G loss: -229.982788]\n",
      "[Epoch 22/2000] [Batch 10/12] [D loss: 37.414856] [G loss: -144.471771]\n",
      "[Epoch 23/2000] [Batch 0/12] [D loss: 41.744629] [G loss: -135.813202]\n",
      "[Epoch 23/2000] [Batch 10/12] [D loss: -11.822826] [G loss: -41.775524]\n",
      "[Epoch 24/2000] [Batch 0/12] [D loss: -20.758377] [G loss: -28.678827]\n",
      "[Epoch 24/2000] [Batch 10/12] [D loss: -57.129646] [G loss: 24.123024]\n",
      "[Epoch 25/2000] [Batch 0/12] [D loss: -61.494793] [G loss: 31.442486]\n",
      "[Epoch 25/2000] [Batch 10/12] [D loss: -85.780281] [G loss: 61.113213]\n",
      "[Epoch 26/2000] [Batch 0/12] [D loss: -90.622894] [G loss: 63.308048]\n",
      "[Epoch 26/2000] [Batch 10/12] [D loss: -99.525497] [G loss: 75.113983]\n",
      "[Epoch 27/2000] [Batch 0/12] [D loss: -93.439980] [G loss: 73.119698]\n",
      "[Epoch 27/2000] [Batch 10/12] [D loss: -93.134567] [G loss: 75.349564]\n",
      "[Epoch 28/2000] [Batch 0/12] [D loss: -87.130188] [G loss: 70.799263]\n",
      "[Epoch 28/2000] [Batch 10/12] [D loss: -85.247002] [G loss: 68.412674]\n",
      "[Epoch 29/2000] [Batch 0/12] [D loss: -79.558167] [G loss: 64.007347]\n",
      "[Epoch 29/2000] [Batch 10/12] [D loss: -83.933189] [G loss: 60.500786]\n",
      "[Epoch 30/2000] [Batch 0/12] [D loss: -74.259560] [G loss: 55.853973]\n",
      "[Epoch 30/2000] [Batch 10/12] [D loss: -73.249596] [G loss: 52.194866]\n",
      "[Epoch 31/2000] [Batch 0/12] [D loss: -64.603256] [G loss: 47.118382]\n",
      "[Epoch 31/2000] [Batch 10/12] [D loss: -58.323013] [G loss: 44.297443]\n",
      "[Epoch 32/2000] [Batch 0/12] [D loss: -52.878212] [G loss: 39.967167]\n",
      "[Epoch 32/2000] [Batch 10/12] [D loss: -53.386604] [G loss: 36.509995]\n",
      "[Epoch 33/2000] [Batch 0/12] [D loss: -52.406101] [G loss: 34.053345]\n",
      "[Epoch 33/2000] [Batch 10/12] [D loss: -45.552265] [G loss: 31.264250]\n",
      "[Epoch 34/2000] [Batch 0/12] [D loss: -41.985645] [G loss: 28.568136]\n",
      "[Epoch 34/2000] [Batch 10/12] [D loss: -42.406078] [G loss: 25.927830]\n",
      "[Epoch 35/2000] [Batch 0/12] [D loss: -41.269951] [G loss: 24.264744]\n",
      "[Epoch 35/2000] [Batch 10/12] [D loss: -40.993591] [G loss: 22.206610]\n",
      "[Epoch 36/2000] [Batch 0/12] [D loss: -39.079609] [G loss: 20.574633]\n",
      "[Epoch 36/2000] [Batch 10/12] [D loss: -34.567879] [G loss: 18.707113]\n",
      "[Epoch 37/2000] [Batch 0/12] [D loss: -37.029545] [G loss: 17.216951]\n",
      "[Epoch 37/2000] [Batch 10/12] [D loss: -32.869049] [G loss: 15.847643]\n",
      "[Epoch 38/2000] [Batch 0/12] [D loss: -28.298721] [G loss: 14.618140]\n",
      "[Epoch 38/2000] [Batch 10/12] [D loss: -34.104733] [G loss: 13.209083]\n",
      "[Epoch 39/2000] [Batch 0/12] [D loss: -29.189583] [G loss: 12.077823]\n",
      "[Epoch 39/2000] [Batch 10/12] [D loss: -32.186577] [G loss: 10.251762]\n",
      "[Epoch 40/2000] [Batch 0/12] [D loss: -34.135056] [G loss: 9.279755]\n",
      "[Epoch 40/2000] [Batch 10/12] [D loss: -38.124023] [G loss: 6.120783]\n",
      "[Epoch 41/2000] [Batch 0/12] [D loss: -35.674503] [G loss: 4.999730]\n",
      "[Epoch 41/2000] [Batch 10/12] [D loss: -54.474335] [G loss: -2.211761]\n",
      "[Epoch 42/2000] [Batch 0/12] [D loss: -58.189556] [G loss: -4.520006]\n",
      "[Epoch 42/2000] [Batch 10/12] [D loss: -101.283081] [G loss: -24.654797]\n",
      "[Epoch 43/2000] [Batch 0/12] [D loss: -110.950897] [G loss: -36.596786]\n",
      "[Epoch 43/2000] [Batch 10/12] [D loss: -146.026169] [G loss: -73.856712]\n",
      "[Epoch 44/2000] [Batch 0/12] [D loss: -112.576622] [G loss: -100.273819]\n",
      "[Epoch 44/2000] [Batch 10/12] [D loss: -78.948242] [G loss: -132.059647]\n",
      "[Epoch 45/2000] [Batch 0/12] [D loss: -21.532364] [G loss: -164.923889]\n",
      "[Epoch 45/2000] [Batch 10/12] [D loss: -21.464806] [G loss: -100.553970]\n",
      "[Epoch 46/2000] [Batch 0/12] [D loss: -3.679741] [G loss: -94.535286]\n",
      "[Epoch 46/2000] [Batch 10/12] [D loss: -29.769562] [G loss: -23.475096]\n",
      "[Epoch 47/2000] [Batch 0/12] [D loss: -36.352722] [G loss: -13.554947]\n",
      "[Epoch 47/2000] [Batch 10/12] [D loss: -58.659893] [G loss: 25.807644]\n",
      "[Epoch 48/2000] [Batch 0/12] [D loss: -62.391899] [G loss: 31.042969]\n",
      "[Epoch 48/2000] [Batch 10/12] [D loss: -68.610977] [G loss: 48.186878]\n",
      "[Epoch 49/2000] [Batch 0/12] [D loss: -72.577530] [G loss: 47.650356]\n",
      "[Epoch 49/2000] [Batch 10/12] [D loss: -69.800598] [G loss: 52.434986]\n",
      "[Epoch 50/2000] [Batch 0/12] [D loss: -68.656548] [G loss: 49.600552]\n",
      "[Epoch 50/2000] [Batch 10/12] [D loss: -69.407974] [G loss: 48.207527]\n",
      "[Epoch 51/2000] [Batch 0/12] [D loss: -59.784367] [G loss: 45.658600]\n",
      "[Epoch 51/2000] [Batch 10/12] [D loss: -65.996239] [G loss: 44.124554]\n",
      "[Epoch 52/2000] [Batch 0/12] [D loss: -59.845802] [G loss: 41.201881]\n",
      "[Epoch 52/2000] [Batch 10/12] [D loss: -56.397530] [G loss: 38.531616]\n",
      "[Epoch 53/2000] [Batch 0/12] [D loss: -53.813217] [G loss: 36.318569]\n",
      "[Epoch 53/2000] [Batch 10/12] [D loss: -48.835857] [G loss: 34.253983]\n",
      "[Epoch 54/2000] [Batch 0/12] [D loss: -50.397560] [G loss: 32.107662]\n",
      "[Epoch 54/2000] [Batch 10/12] [D loss: -48.111732] [G loss: 30.011040]\n",
      "[Epoch 55/2000] [Batch 0/12] [D loss: -44.405403] [G loss: 28.353840]\n",
      "[Epoch 55/2000] [Batch 10/12] [D loss: -39.468403] [G loss: 26.076593]\n",
      "[Epoch 56/2000] [Batch 0/12] [D loss: -41.056419] [G loss: 24.728409]\n",
      "[Epoch 56/2000] [Batch 10/12] [D loss: -38.348125] [G loss: 22.907665]\n",
      "[Epoch 57/2000] [Batch 0/12] [D loss: -42.206009] [G loss: 21.277884]\n",
      "[Epoch 57/2000] [Batch 10/12] [D loss: -39.709446] [G loss: 18.965630]\n",
      "[Epoch 58/2000] [Batch 0/12] [D loss: -41.501339] [G loss: 17.662096]\n",
      "[Epoch 58/2000] [Batch 10/12] [D loss: -41.396671] [G loss: 13.018957]\n",
      "[Epoch 59/2000] [Batch 0/12] [D loss: -38.109085] [G loss: 11.253855]\n",
      "[Epoch 59/2000] [Batch 10/12] [D loss: -51.860889] [G loss: -1.696244]\n",
      "[Epoch 60/2000] [Batch 0/12] [D loss: -54.115341] [G loss: -5.733379]\n",
      "[Epoch 60/2000] [Batch 10/12] [D loss: -85.935577] [G loss: -45.773129]\n",
      "[Epoch 61/2000] [Batch 0/12] [D loss: -84.121208] [G loss: -64.900902]\n",
      "[Epoch 61/2000] [Batch 10/12] [D loss: -95.081024] [G loss: -117.925797]\n",
      "[Epoch 62/2000] [Batch 0/12] [D loss: -51.575974] [G loss: -152.844696]\n",
      "[Epoch 62/2000] [Batch 10/12] [D loss: -33.343987] [G loss: -106.253044]\n",
      "[Epoch 63/2000] [Batch 0/12] [D loss: -14.489899] [G loss: -102.292343]\n",
      "[Epoch 63/2000] [Batch 10/12] [D loss: -36.301781] [G loss: -18.750719]\n",
      "[Epoch 64/2000] [Batch 0/12] [D loss: -40.057621] [G loss: -8.438519]\n",
      "[Epoch 64/2000] [Batch 10/12] [D loss: -59.991905] [G loss: 28.811111]\n",
      "[Epoch 65/2000] [Batch 0/12] [D loss: -62.315529] [G loss: 32.947475]\n",
      "[Epoch 65/2000] [Batch 10/12] [D loss: -67.891434] [G loss: 44.357620]\n",
      "[Epoch 66/2000] [Batch 0/12] [D loss: -64.645470] [G loss: 43.793419]\n",
      "[Epoch 66/2000] [Batch 10/12] [D loss: -64.168015] [G loss: 45.422016]\n",
      "[Epoch 67/2000] [Batch 0/12] [D loss: -62.305672] [G loss: 42.780853]\n",
      "[Epoch 67/2000] [Batch 10/12] [D loss: -60.866837] [G loss: 42.075512]\n",
      "[Epoch 68/2000] [Batch 0/12] [D loss: -61.471039] [G loss: 39.226582]\n",
      "[Epoch 68/2000] [Batch 10/12] [D loss: -54.779095] [G loss: 37.855801]\n",
      "[Epoch 69/2000] [Batch 0/12] [D loss: -53.125229] [G loss: 35.316860]\n",
      "[Epoch 69/2000] [Batch 10/12] [D loss: -53.936783] [G loss: 33.912979]\n"
     ]
    }
   ],
   "source": [
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "\n",
    "batches_done = 0\n",
    "for epoch in range(opt.n_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        def __getitem__(self, idx):\n",
    "            try:\n",
    "                img, label = load_img(idx)\n",
    "            except:\n",
    "                return None\n",
    "            return [img, label]\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        fake_imgs = generator(z).detach()\n",
    "        # Adversarial loss\n",
    "        loss_D = -torch.mean(discriminator(real_imgs)) + torch.mean(discriminator(fake_imgs))\n",
    "\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Clip weights of discriminator\n",
    "        for p in discriminator.parameters():\n",
    "            p.data.clamp_(-opt.clip_value, opt.clip_value)\n",
    "\n",
    "        # Train the generator every n_critic iterations\n",
    "        if i % opt.n_critic == 0:\n",
    "\n",
    "            # -----------------\n",
    "            #  Train Generator\n",
    "            # -----------------\n",
    "\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            # Generate a batch of images\n",
    "            gen_imgs = generator(z)\n",
    "            # Adversarial loss\n",
    "            loss_G = -torch.mean(discriminator(gen_imgs))\n",
    "\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                % (epoch, opt.n_epochs, batches_done % len(dataloader), len(dataloader), loss_D.item(), loss_G.item())\n",
    "            )\n",
    "\n",
    "        if batches_done % opt.sample_interval == 0:\n",
    "            save_image(gen_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)\n",
    "        batches_done += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b08d2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e72cceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
