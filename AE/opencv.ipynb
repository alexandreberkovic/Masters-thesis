{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b59c6e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c8dd7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as  nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0a6d93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch import load_state_dict_from_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eebc8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.5.1\n",
      "Torchvision Version:  0.6.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18956244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "223f4f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b560d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the architecture by modifying resnet.\n",
    "# Original code is here http://tiny.cc/8zpmmz \n",
    "class ResNet101(models.ResNet):\n",
    "    def __init__(self, num_classes=1000, pretrained=True, **kwargs):\n",
    "        # Start with the standard resnet101\n",
    "        super().__init__(\n",
    "            block=models.resnet.Bottleneck,\n",
    "            layers=[3, 4, 23, 3],\n",
    "            num_classes=num_classes,\n",
    "            **kwargs\n",
    "        )\n",
    "        if pretrained:\n",
    "            state_dict = load_state_dict_from_url(\n",
    "                models.resnet.model_urls['resnet101'],\n",
    "                progress=True\n",
    "            )\n",
    "            self.load_state_dict(state_dict)\n",
    "\n",
    "    # Reimplementing forward pass.\n",
    "    # Replacing the forward inference defined here \n",
    "    # http://tiny.cc/23pmmz\n",
    "    def _forward_impl(self, x):\n",
    "        # Standard forward for resnet\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        # Notice there is no forward pass through the original classifier.\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de40611b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-8c6c29fb50eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Running the model inference'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "# initialize our implementation of ResNet\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "for batch in tqdm(dataloader, desc='Running the model inference'):\n",
    "    images = batch['image'].to(device)\n",
    "    labels += batch['label']\n",
    "    image_paths += batch['image_path']\n",
    "\n",
    "    output = model.forward(images)\n",
    "\n",
    "    current_outputs = output.cpu().numpy()\n",
    "    features = np.concatenate((outputs, current_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255b27c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2).fit_transform(features)# scale and move the coordinates so they fit [0; 1] range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b855773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_to_01_range(x):\n",
    "    # compute the distribution range\n",
    "    value_range = (np.max(x) - np.min(x))\n",
    "\n",
    "    # move the distribution so that it starts from zero\n",
    "    # by extracting the minimal value from all its values\n",
    "    starts_from_zero = x - np.min(x)\n",
    "\n",
    "    # make the distribution fit [0; 1] by dividing by its range\n",
    "    return starts_from_zero / value_range\n",
    "\n",
    "# extract x and y coordinates representing the positions of the images on T-SNE plot\n",
    "tx = tsne[:, 0]\n",
    "ty = tsne[:, 1]\n",
    "\n",
    "tx = scale_to_01_range(tx)\n",
    "ty = scale_to_01_range(ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d13be18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a matplotlib plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# for every class, we'll add a scatter plot separately\n",
    "for label in colors_per_class:\n",
    "    # find the samples of the current class in the data\n",
    "    indices = [i for i, l in enumerate(labels) if l == label]\n",
    "\n",
    "    # extract the coordinates of the points of this class only\n",
    "    current_tx = np.take(tx, indices)\n",
    "    current_ty = np.take(ty, indices)\n",
    "\n",
    "    # convert the class color to matplotlib format\n",
    "    color = np.array(colors_per_class[label], dtype=np.float) / 255\n",
    "\n",
    "    # add a scatter plot with the corresponding color and label\n",
    "    ax.scatter(current_tx, current_ty, c=color, label=label)\n",
    "\n",
    "# build a legend using the labels we set previously\n",
    "ax.legend(loc='best')\n",
    "\n",
    "# finally, show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43ac905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3b2e79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p36",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
