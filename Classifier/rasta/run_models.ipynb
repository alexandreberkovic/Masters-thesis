{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec1118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d8d6251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.alexnet import decaf,alexnet\n",
    "from models.processing import train_model_from_directory\n",
    "from models.custom_resnets import *\n",
    "from models.inceptionV4 import inception_v4\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import os\n",
    "from os.path import join\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06b32eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = os.path.dirname(__file__)\n",
    "\n",
    "# PARSING ARGUMENTS\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Description')\n",
    "\n",
    "parser.add_argument('-m', action=\"store\", default='custom_resnet',dest='model_name',help='Name of the model [alexnet_empty|decaf6|resnet|inception|inceptionv4|resnet2|empty_resnet|resnet_dropout|resnet_18|resnet_34|resnet_101|resnet_152|custom_resnet')\n",
    "parser.add_argument('-b', action=\"store\", default=32, type=int,dest='batch_size',help='Size of the batch.')\n",
    "parser.add_argument('-e', action=\"store\",default=10,type=int,dest='epochs',help='Number of epochs')\n",
    "parser.add_argument('-f', action=\"store\", default=False, type=bool,dest='horizontal_flip',help='Set horizontal flip or not [True|False]')\n",
    "parser.add_argument('-n', action=\"store\", default=20, type=int,dest='n_layers_trainable',help='Set the number of last trainable layers')\n",
    "parser.add_argument('-d', action=\"store\", default=0, type=float,dest='dropout_rate',help='Set the dropout_rate')\n",
    "\n",
    "parser.add_argument('-p', action=\"store\",dest='preprocessing',help='Set imagenet preprocessing or not')\n",
    "\n",
    "parser.add_argument('--distortions', action=\"store\", type=float,dest='disto',default=0.,help='Activate distortions or not')\n",
    "\n",
    "parser.add_argument('--train_path', action=\"store\", default=join('/home/ec2-user/SageMaker/wikiart_binary/train'),dest='training_path',help='Path of the training data directory')\n",
    "parser.add_argument('--val_path', action=\"store\", default=join('/home/ec2-user/SageMaker/wikiart_binary/test'),dest='test_path',help='Path of the test data directory')\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24641644",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = args.model_name\n",
    "batch_size = args.batch_size\n",
    "epochs = args.epochs\n",
    "flip = args.horizontal_flip\n",
    "TRAINING_PATH = args.training_path\n",
    "VAL_PATH = args.test_path\n",
    "n_layers_trainable = args.n_layers_trainable\n",
    "dropout_rate = args.dropout_rate\n",
    "\n",
    "params = vars(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e69d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING MODEL\n",
    "number_classes = 2\n",
    "if model_name =='alexnet_empty':\n",
    "    K.set_image_data_format('channels_first')\n",
    "    size = (227, 227)\n",
    "    model = alexnet(weights=None)\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "elif model_name =='decaf6':\n",
    "    K.set_image_data_format('channels_first')\n",
    "    size = (227, 227)\n",
    "    base_model = decaf()\n",
    "    predictions = Dense(number_classes, activation='softmax')(base_model.output)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "elif model_name =='resnet':\n",
    "    K.set_image_data_format('channels_last')\n",
    "    size = (224,224)\n",
    "\n",
    "    base_model = resnet_trained(n_layers_trainable)\n",
    "    predictions = Dense(number_classes, activation='softmax')(base_model.output)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "elif model_name =='inception':\n",
    "    K.set_image_data_format('channels_last')\n",
    "    size = (224,224)\n",
    "\n",
    "    base_model = inception(n_layers_trainable)\n",
    "    predictions = Dense(number_classes, activation='softmax')(base_model.output)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "elif model_name =='inceptionv4':\n",
    "    K.set_image_data_format('channels_last')\n",
    "    size = (299,299)\n",
    "    model = inception_v4()\n",
    "\n",
    "\n",
    "elif model_name=='resnet2':\n",
    "    K.set_image_data_format('channels_last')\n",
    "    size=(224,224)\n",
    "    base_model = resnet_trained_2(n_layers_trainable)\n",
    "    predictions = Dense(number_classes, activation='softmax')(base_model.output)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "elif model_name =='empty_resnet':\n",
    "    K.set_image_data_format('channels_last')\n",
    "    size = (224,224)\n",
    "\n",
    "    base_model = empty_resnet()\n",
    "    predictions = Dense(number_classes, activation='softmax')(base_model.output)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "elif model_name=='resnet_dropout':\n",
    "    K.set_image_data_format('channels_last')\n",
    "    size = (224, 224)\n",
    "    base_model = resnet_dropout(dp_rate=dropout_rate,n_retrain_layers=n_layers_trainable)\n",
    "    predictions = Dense(number_classes, activation='softmax')(base_model.output)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "elif model_name=='resnet_18':\n",
    "    size = (224, 224)\n",
    "    K.set_image_data_format('channels_last')\n",
    "    model =  resnet18()\n",
    "\n",
    "elif model_name=='resnet_34':\n",
    "    size = (224, 224)\n",
    "    K.set_image_data_format('channels_last')\n",
    "    model =  resnet34()\n",
    "\n",
    "elif model_name=='resnet_101':\n",
    "    size = (224, 224)\n",
    "    K.set_image_data_format('channels_last')\n",
    "    model =  resnet101()\n",
    "\n",
    "elif model_name=='resnet_152':\n",
    "    size = (224, 224)\n",
    "    K.set_image_data_format('channels_last')\n",
    "    model =  resnet152()\n",
    "elif model_name == 'custom_resnet':\n",
    "    size = (224, 224)\n",
    "    K.set_image_data_format('channels_last')\n",
    "    model = custom_resnet(dp_rate=dropout_rate)\n",
    "else:\n",
    "    print(\"The model name doesn't exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebcbafff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37629 images belonging to 2 classes.\n",
      "Found 18530 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "   1/1175 [..............................] - ETA: 0s - loss: 0.9861 - accuracy: 0.3438WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "1175/1175 [==============================] - ETA: 0s - loss: 0.3963 - accuracy: 0.8357WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1175/1175 [==============================] - 543s 462ms/step - loss: 0.3963 - accuracy: 0.8357 - val_loss: 0.3326 - val_accuracy: 0.8615\n",
      "Epoch 2/10\n",
      "1175/1175 [==============================] - ETA: 0s - loss: 0.3521 - accuracy: 0.8545WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1175/1175 [==============================] - 180s 153ms/step - loss: 0.3521 - accuracy: 0.8545 - val_loss: 0.3680 - val_accuracy: 0.8542\n",
      "Epoch 3/10\n",
      "1175/1175 [==============================] - ETA: 0s - loss: 0.3417 - accuracy: 0.8597WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1175/1175 [==============================] - 183s 156ms/step - loss: 0.3417 - accuracy: 0.8597 - val_loss: 0.3339 - val_accuracy: 0.8636\n",
      "Epoch 4/10\n",
      "1175/1175 [==============================] - ETA: 0s - loss: 0.3367 - accuracy: 0.8635WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1175/1175 [==============================] - 183s 156ms/step - loss: 0.3367 - accuracy: 0.8635 - val_loss: 0.3434 - val_accuracy: 0.8607\n",
      "Epoch 5/10\n",
      "1175/1175 [==============================] - ETA: 0s - loss: 0.3315 - accuracy: 0.8641WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1175/1175 [==============================] - 182s 155ms/step - loss: 0.3315 - accuracy: 0.8641 - val_loss: 0.3595 - val_accuracy: 0.8573\n",
      "Epoch 6/10\n",
      "1175/1175 [==============================] - ETA: 0s - loss: 0.3311 - accuracy: 0.8653WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1175/1175 [==============================] - 183s 156ms/step - loss: 0.3311 - accuracy: 0.8653 - val_loss: 0.3424 - val_accuracy: 0.8599\n",
      "Epoch 7/10\n",
      "1175/1175 [==============================] - ETA: 0s - loss: 0.3275 - accuracy: 0.8654WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1175/1175 [==============================] - 184s 156ms/step - loss: 0.3275 - accuracy: 0.8654 - val_loss: 0.3641 - val_accuracy: 0.8582\n",
      "Epoch 8/10\n",
      "1175/1175 [==============================] - ETA: 0s - loss: 0.3274 - accuracy: 0.8678WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1175/1175 [==============================] - 184s 156ms/step - loss: 0.3274 - accuracy: 0.8678 - val_loss: 0.3725 - val_accuracy: 0.8513\n",
      "Epoch 9/10\n",
      "1175/1175 [==============================] - ETA: 0s - loss: 0.3254 - accuracy: 0.8672WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1175/1175 [==============================] - 184s 156ms/step - loss: 0.3254 - accuracy: 0.8672 - val_loss: 0.3499 - val_accuracy: 0.8601\n",
      "Epoch 10/10\n",
      "1175/1175 [==============================] - ETA: 0s - loss: 0.3235 - accuracy: 0.8683WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1175/1175 [==============================] - 184s 157ms/step - loss: 0.3235 - accuracy: 0.8683 - val_loss: 0.3545 - val_accuracy: 0.8607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x7f550f7f8240>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "train_model_from_directory(TRAINING_PATH,model,model_name=model_name,target_size=size,validation_path=VAL_PATH,epochs = epochs,batch_size = batch_size,horizontal_flip=flip,params=params,preprocessing=args.preprocessing,distortions=args.disto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8943e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37629 images belonging to 2 classes.\n",
      "Found 18530 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "   2/1175 [..............................] - ETA: 3:14 - loss: 0.3924 - accuracy: 0.8594WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1167s vs `on_train_batch_end` time: 0.2152s). Check your callbacks.\n",
      "1175/1175 [==============================] - ETA: 0s - loss: 0.3250 - accuracy: 0.8709WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1175/1175 [==============================] - 181s 154ms/step - loss: 0.3250 - accuracy: 0.8709 - val_loss: 0.3467 - val_accuracy: 0.8567\n",
      "Epoch 2/10\n",
      "1175/1175 [==============================] - ETA: 0s - loss: 0.3230 - accuracy: 0.8686WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1175/1175 [==============================] - 183s 156ms/step - loss: 0.3230 - accuracy: 0.8686 - val_loss: 0.3955 - val_accuracy: 0.8541\n",
      "Epoch 3/10\n",
      "1175/1175 [==============================] - ETA: 0s - loss: 0.3237 - accuracy: 0.8683WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1175/1175 [==============================] - 184s 157ms/step - loss: 0.3237 - accuracy: 0.8683 - val_loss: 0.3738 - val_accuracy: 0.8522\n",
      "Epoch 4/10\n",
      "1175/1175 [==============================] - ETA: 0s - loss: 0.3245 - accuracy: 0.8686WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1175/1175 [==============================] - 184s 157ms/step - loss: 0.3245 - accuracy: 0.8686 - val_loss: 0.3508 - val_accuracy: 0.8602\n",
      "Epoch 5/10\n",
      " 470/1175 [===========>..................] - ETA: 1:14 - loss: 0.3203 - accuracy: 0.8707"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "train_model_from_directory(TRAINING_PATH,model,model_name=model_name,target_size=size,validation_path=VAL_PATH,epochs = epochs,batch_size = batch_size,horizontal_flip=flip,params=params,preprocessing=args.preprocessing,distortions=args.disto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928cd161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
