{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a02b6abb",
   "metadata": {},
   "source": [
    "# Deep Convolutional Neural Network for Art Classification with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4d8347e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import tarfile\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import random_split\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pathlib\n",
    "import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "56c0f8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name='CNN_classifier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "78ae1489",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_str = '/Users/alexandreberkovic/Desktop/Year_4/Masters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "94494c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(path_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fbeae227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Research',\n",
       " '.DS_Store',\n",
       " 'classifier for art.pdf',\n",
       " 'Dataset',\n",
       " 'Master projects.xlsx',\n",
       " 'Interim',\n",
       " 'Repo']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e743c630",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folders = Path(path_str+'/'+'Dataset/wikiart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7525e4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove DS_Store file\n",
    "folders = list(os.listdir(img_folders))\n",
    "folders.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d48e88de",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_folder = Path(path_str+'/'+'Dataset/wikiart/Trial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2ff21c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folders = specific_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "81d58f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(809, 1070)\n",
      "(552, 750)\n",
      "(369, 420)\n",
      "(331, 500)\n",
      "(331, 573)\n",
      "(417, 600)\n",
      "(1103, 903)\n"
     ]
    }
   ],
   "source": [
    "images = [file for file in os.listdir(img_folders) if file.endswith(('jpeg', 'png', 'jpg'))]\n",
    "for image in images:\n",
    "    img = Image.open(Path(str(img_folders)+'/'+image))\n",
    "    print(img.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2c9fe2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(path,cnn_size):\n",
    "        \n",
    "    images = [file for file in os.listdir(path) if file.endswith(('jpeg', 'png', 'jpg'))]\n",
    "    \n",
    "    for image in images:\n",
    "        img = Image.open(Path(str(img_folders)+'/'+image))\n",
    "        \n",
    "        if img.size[0] >= img.size[1] and img.size[1] > cnn_size:\n",
    "\n",
    "            fixed_height = cnn_size\n",
    "            height_percent = (fixed_height / float(img.size[1]))\n",
    "#             print(height_percent)\n",
    "            width_size = int((float(img.size[0]) * float(height_percent)))\n",
    "#             print(img.size)\n",
    "            img = img.resize((width_size, fixed_height), PIL.Image.NEAREST)\n",
    "#             image.save('resized_nearest.jpg')\n",
    "#             print(img.size)\n",
    "            img.save(\"resized_\"+image, optimize=True, quality=90)\n",
    "    \n",
    "        elif img.size[0] < img.size[1] and img.size[0] > cnn_size:\n",
    "            fixed_width = cnn_size\n",
    "            width_percent = (fixed_width / float(img.size[0]))\n",
    "            height_size = int((float(img.size[1]) * float(width_percent)))\n",
    "#             print(img.size)\n",
    "            img = img.resize((fixed_width, height_size), PIL.Image.NEAREST)\n",
    "#             image.save('resized_nearest.jpg')\n",
    "#             print(img.size)\n",
    "            img.save(\"resized_\"+image, optimize=True, quality=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8656a654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(809, 1070)\n",
      "(256, 338)\n",
      "(552, 750)\n",
      "(256, 347)\n",
      "(369, 420)\n",
      "(256, 291)\n",
      "(331, 500)\n",
      "(256, 386)\n",
      "(331, 573)\n",
      "(256, 443)\n",
      "(417, 600)\n",
      "(256, 368)\n",
      "0.28349944629014395\n",
      "(1103, 903)\n",
      "(312, 256)\n"
     ]
    }
   ],
   "source": [
    "# try with compressed image, cropped image upper and lower\n",
    "\n",
    "resize(img_folders,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9576d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e93e0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
