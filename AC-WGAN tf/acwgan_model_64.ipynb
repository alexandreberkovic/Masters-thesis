{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34f2c085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Creates batches of images to feed into the training network conditioned by genre, uses upsampling when creating batches to account for uneven distributions '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Creates batches of images to feed into the training network conditioned by genre, uses upsampling when creating batches to account for uneven distributions \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73aa22d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow-gpu==1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ba2a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c520c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dimension of images you want to be passed in to the network\n",
    "DIM = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9a4b880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your own path to images\n",
    "# src_img_path  = Path('/home/ec2-user/SageMaker/genre-128')\n",
    "src_img_path  = Path('/home/ec2-user/SageMaker/portrait_landscape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b00ed3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '.ipynb_checkpoints', '0']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(src_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e5b169a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14981"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(os.path.join(src_img_path,'0')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f9f7e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary should be updated to hold the absolute number of images associated with each genre used during training\n",
    "styles = {\n",
    "    \"portraits\": 14980,\n",
    "    \"landscapes\": 14971\n",
    "}\n",
    "\n",
    "styleNum = {\n",
    "    \"portraits\": 0,\n",
    "    \"landscapes\": 1\n",
    "}\n",
    "    \n",
    "curPos = {\n",
    "    \"portraits\": 0,\n",
    "    \"landscapes\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76e4c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "testNums = {}\n",
    "trainNums = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b0ef53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test set of images made up of 1/20 of the images (per genre)\n",
    "for k, v in styles.items():\n",
    "    # put a twentieth of paintings in here\n",
    "    nums = range(v)\n",
    "    random.shuffle(list(nums))\n",
    "    testNums[k] = nums[0 : v // 20]\n",
    "    trainNums[k] = nums[v // 20 :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8bf6b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf_gen(gen):\n",
    "    while True:\n",
    "        for (images, labels) in gen():\n",
    "            yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f82c61ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator(files, batch_size, n_classes): # add genre parameter\n",
    "    if batch_size % n_classes != 0:\n",
    "        raise ValueError(\n",
    "            \"Batch size {} must be divisible by num classes {}\".format(batch_size, n_classes)\n",
    "        )\n",
    "\n",
    "    class_batch = batch_size // n_classes\n",
    "\n",
    "    generators = []\n",
    "\n",
    "    def get_epoch():\n",
    "\n",
    "        while True:\n",
    "\n",
    "            images = np.zeros((batch_size, 3, DIM, DIM), dtype=\"int32\")\n",
    "            labels = np.zeros((batch_size, n_classes))\n",
    "            n = 0\n",
    "            for style in styles:\n",
    "#             for style in genre:\n",
    "                styleLabel = styleNum[style]\n",
    "                curr = curPos[style]\n",
    "                for _ in range(class_batch):\n",
    "                    if curr == styles[style]:\n",
    "                        curr = 0\n",
    "                        random.shuffle(list(files[style]))\n",
    "                    img_path = str(Path(src_img_path, str(styleLabel), str(curr) + \".png\"))\n",
    "                    image = Image.open(img_path).convert(mode=\"RGB\")\n",
    "                    image = np.asarray(image)\n",
    "\n",
    "                    images[n % batch_size] = image.transpose(2, 0, 1)\n",
    "                    labels[n % batch_size, int(styleLabel)] = 1\n",
    "                    n += 1\n",
    "                    curr += 1\n",
    "                curPos[style] = curr\n",
    "\n",
    "            # randomize things but keep relationship between a conditioning vector and its associated image\n",
    "            rng_state = np.random.get_state()\n",
    "            np.random.shuffle(images)\n",
    "            np.random.set_state(rng_state)\n",
    "            np.random.shuffle(labels)\n",
    "            yield (images, labels)\n",
    "\n",
    "    return get_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75752fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(batch_size):\n",
    "    return (\n",
    "        make_generator(trainNums, batch_size, len(styles)),\n",
    "        make_generator(testNums, batch_size, len(styles)),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8e0504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import time\n",
    "import functools\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tflib as lib\n",
    "import tflib.ops.linear\n",
    "import tflib.ops.conv2d\n",
    "import tflib.ops.batchnorm\n",
    "import tflib.ops.deconv2d\n",
    "import tflib.save_images\n",
    "# import tflib.wikiart_genre\n",
    "import tflib.ops.layernorm\n",
    "import tflib.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eb38d301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade tensorflow-gpu==1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "19fdd28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d24f06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n",
      "1.15.5\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.gpu_device_name())\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "03ac7a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ddea39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uppercase local vars:\n",
      "\tBATCH_SIZE: 84\n",
      "\tCLASSES: 2\n",
      "\tCRITIC_ITERS: 5\n",
      "\tDEVICES: ['/gpu:0']\n",
      "\tDIM: 64\n",
      "\tITERS: 200000\n",
      "\tLAMBDA: 10\n",
      "\tMODE: acwgan\n",
      "\tN_GPUS: 1\n",
      "\tOUTPUT_DIM: 12288\n",
      "\tPREITERATIONS: 2000\n"
     ]
    }
   ],
   "source": [
    "MODE = \"acwgan\"  # dcgan, wgan, wgan-gp, lsgan\n",
    "genre = ['portraits','landscapes']\n",
    "DIM = 64  # Model dimensionality\n",
    "CRITIC_ITERS = 5  # How many iterations to train the critic for, increase it to 50 later\n",
    "N_GPUS = 1  # Number of GPUs\n",
    "BATCH_SIZE = 84  # Batch size. Must be a multiple of CLASSES and N_GPUS\n",
    "ITERS = 200000  # How many iterations to train for\n",
    "LAMBDA = 10  # Gradient penalty lambda hyperparameter\n",
    "OUTPUT_DIM = DIM * DIM * 3  # Number of pixels in each image\n",
    "CLASSES = len(genre)  # Number of classes, for genres probably 14\n",
    "PREITERATIONS = 2000  # Number of preiteration training cycles to run\n",
    "lib.print_model_settings(locals().copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f83c2cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that directory exists where ground truth and plots will be saved to.\n",
    "Path('generated').mkdir(parents=True, exist_ok=True)\n",
    "Path('models').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "868b2927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeneratorAndDiscriminator():\n",
    "    return kACGANGenerator, kACGANDiscriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f79546cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICES = [\"/gpu:{}\".format(i) for i in range(N_GPUS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "afa76427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeakyReLU(x, alpha=0.2):\n",
    "    return tf.maximum(alpha * x, x)\n",
    "\n",
    "\n",
    "def ReLULayer(name, n_in, n_out, inputs):\n",
    "    output = lib.ops.linear.Linear(\n",
    "        name + \".Linear\", n_in, n_out, inputs, initialization=\"he\"\n",
    "    )\n",
    "    return tf.nn.relu(output)\n",
    "\n",
    "\n",
    "def LeakyReLULayer(name, n_in, n_out, inputs):\n",
    "    output = lib.ops.linear.Linear(\n",
    "        name + \".Linear\", n_in, n_out, inputs, initialization=\"he\"\n",
    "    )\n",
    "    return LeakyReLU(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f723688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Batchnorm(name, axes, inputs):\n",
    "\n",
    "    if (\"Discriminator\" in name) and (MODE == \"wgan-gp\" or MODE == \"acwgan\"):\n",
    "        if axes != [0, 2, 3]:\n",
    "            raise Exception(\"Layernorm over non-standard axes is unsupported\")\n",
    "        return lib.ops.layernorm.Layernorm(name, [1, 2, 3], inputs)\n",
    "    else:\n",
    "        return lib.ops.batchnorm.Batchnorm(name, axes, inputs, fused=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ead48aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixcnn_gated_nonlinearity(name, output_dim, a, b, c=None, d=None):\n",
    "    if c is not None and d is not None:\n",
    "        a = a + c\n",
    "        b = b + d\n",
    "\n",
    "    result = tf.sigmoid(a) * tf.tanh(b)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44875216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SubpixelConv2D(*args, **kwargs):\n",
    "    kwargs[\"output_dim\"] = 4 * kwargs[\"output_dim\"]\n",
    "    output = lib.ops.conv2d.Conv2D(*args, **kwargs)\n",
    "    output = tf.transpose(output, [0, 2, 3, 1])\n",
    "    output = tf.depth_to_space(output, 2)\n",
    "    output = tf.transpose(output, [0, 3, 1, 2])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "781d5e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResidualBlock(\n",
    "    name, input_dim, output_dim, filter_size, inputs, resample=None, he_init=True\n",
    "):\n",
    "    \"\"\"\n",
    "    resample: None, 'down', or 'up'\n",
    "    \"\"\"\n",
    "    if resample == \"down\":\n",
    "        conv_shortcut = functools.partial(lib.ops.conv2d.Conv2D, stride=2)\n",
    "        conv_1 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim, output_dim=input_dim // 2\n",
    "        )\n",
    "        conv_1b = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D,\n",
    "            input_dim=input_dim // 2,\n",
    "            output_dim=output_dim // 2,\n",
    "            stride=2,\n",
    "        )\n",
    "        conv_2 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=output_dim // 2, output_dim=output_dim\n",
    "        )\n",
    "    elif resample == \"up\":\n",
    "        conv_shortcut = SubpixelConv2D\n",
    "        conv_1 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim, output_dim=input_dim // 2\n",
    "        )\n",
    "        conv_1b = functools.partial(\n",
    "            lib.ops.deconv2d.Deconv2D,\n",
    "            input_dim=input_dim // 2,\n",
    "            output_dim=output_dim // 2,\n",
    "        )\n",
    "        conv_2 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=output_dim // 2, output_dim=output_dim\n",
    "        )\n",
    "    elif resample == None:\n",
    "        conv_shortcut = lib.ops.conv2d.Conv2D\n",
    "        conv_1 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim, output_dim=input_dim // 2\n",
    "        )\n",
    "        conv_1b = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim // 2, output_dim=output_dim // 2\n",
    "        )\n",
    "        conv_2 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim // 2, output_dim=output_dim\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"invalid resample value\")\n",
    "\n",
    "    if output_dim == input_dim and resample == None:\n",
    "        shortcut = inputs  # Identity skip-connection\n",
    "    else:\n",
    "        shortcut = conv_shortcut(\n",
    "            name + \".Shortcut\",\n",
    "            input_dim=input_dim,\n",
    "            output_dim=output_dim,\n",
    "            filter_size=1,\n",
    "            he_init=False,\n",
    "            biases=True,\n",
    "            inputs=inputs,\n",
    "        )\n",
    "\n",
    "    output = inputs\n",
    "    output = tf.nn.relu(output)\n",
    "    output = conv_1(\n",
    "        name + \".Conv1\", filter_size=1, inputs=output, he_init=he_init, weightnorm=False\n",
    "    )\n",
    "    output = tf.nn.relu(output)\n",
    "    output = conv_1b(\n",
    "        name + \".Conv1B\",\n",
    "        filter_size=filter_size,\n",
    "        inputs=output,\n",
    "        he_init=he_init,\n",
    "        weightnorm=False,\n",
    "    )\n",
    "    output = tf.nn.relu(output)\n",
    "    output = conv_2(\n",
    "        name + \".Conv2\",\n",
    "        filter_size=1,\n",
    "        inputs=output,\n",
    "        he_init=he_init,\n",
    "        weightnorm=False,\n",
    "        biases=False,\n",
    "    )\n",
    "    output = Batchnorm(name + \".BN\", [0, 2, 3], output)\n",
    "\n",
    "    return shortcut + (0.3 * output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d7a7e37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kACGANGenerator(\n",
    "    n_samples,\n",
    "    numClasses,\n",
    "    labels,\n",
    "    noise=None,\n",
    "    dim=DIM,\n",
    "    bn=True,\n",
    "    nonlinearity=tf.nn.relu,\n",
    "    condition=None,\n",
    "):\n",
    "    lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.linear.set_weights_stdev(0.02)\n",
    "    if noise is None:\n",
    "        noise = tf.random_normal([n_samples, 128])\n",
    "\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    noise = tf.concat([noise, labels], 1)\n",
    "\n",
    "    output = lib.ops.linear.Linear(\n",
    "        \"Generator.Input\", 128 + numClasses, 8 * 4 * 4 * dim * 2, noise\n",
    "    )  # probs need to recalculate dimensions\n",
    "    print('Generator output 1: ', output, output.shape)\n",
    "    output = tf.reshape(output, [-1, 8 * dim * 2, 4, 4])\n",
    "#     output = tf.reshape(output, [-1, dim , 4, 4])\n",
    "    print('Generator output 1 reshape: ', output, output.shape)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN1\", [0, 2, 3], output)\n",
    "        print('Generator output 1 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond1\", numClasses, 8 * 4 * 4 * dim * 2, labels, biases=False\n",
    "    )\n",
    "    condition = tf.reshape(condition, [-1, 8 * dim * 2, 4, 4])\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl1\",\n",
    "        8 * dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2],\n",
    "        condition[:, ::2],\n",
    "        condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 1 final: ', output)\n",
    "    print('Structure 1: ', 8 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "#######################\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.2\", 8 * dim, 4 * dim * 2, 5, output)\n",
    "    print('Generator output 2: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN2\", [0, 2, 3], output)\n",
    "        print('Generator output 2 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond2\", numClasses, 4 * 8 * 8 * dim * 2, labels\n",
    "    )\n",
    "    condition = tf.reshape(condition, [-1, 4 * dim * 2, 8, 8])\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl2\",\n",
    "        4 * dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2],\n",
    "        condition[:, ::2],\n",
    "        condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 2 final: ', output)\n",
    "    print('Structure 2: ', 4 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "#######################\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.3\", 4 * dim, 2 * dim * 2, 5, output)\n",
    "    print('Generator output 3: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN3\", [0, 2, 3], output)\n",
    "        print('Generator output 3 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond3\", numClasses, 2 * 16 * 16 * dim * 2, labels\n",
    "    )\n",
    "    condition = tf.reshape(condition, [-1, 2 * dim * 2, 16, 16])\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl3\",\n",
    "        2 * dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2],\n",
    "        condition[:, ::2],\n",
    "        condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 3 final: ', output)\n",
    "    print('Structure 3: ', 2 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "#######################\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.4\", 2 * dim, dim * 2, 5, output)\n",
    "    print('Generator output 4: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN4\", [0, 2, 3], output)\n",
    "        print('Generator output 4 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond4\", numClasses, 32 * 32 * dim * 2, labels\n",
    "    )\n",
    "    condition = tf.reshape(condition, [-1, 2 * dim, 32, 32])\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl4\",\n",
    "        dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2],\n",
    "        condition[:, ::2],\n",
    "        condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 4 final: ', output)\n",
    "    print('Structure 4: ', dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "#######################\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.5\", dim, 3, 5, output)\n",
    "    print('Generator output 6: ', output)\n",
    "    output = tf.tanh(output)\n",
    "    print('Generator output final: ', output)\n",
    "    lib.ops.conv2d.unset_weights_stdev()\n",
    "    lib.ops.deconv2d.unset_weights_stdev()\n",
    "    lib.ops.linear.unset_weights_stdev()\n",
    "\n",
    "    return tf.reshape(output, [-1, OUTPUT_DIM]), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b2d9ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prints removed\n",
    "# def kACGANGenerator(\n",
    "#     n_samples,\n",
    "#     numClasses,\n",
    "#     labels,\n",
    "#     noise=None,\n",
    "#     dim=DIM,\n",
    "#     bn=True,\n",
    "#     nonlinearity=tf.nn.relu,\n",
    "#     condition=None,\n",
    "# ):\n",
    "#     lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.linear.set_weights_stdev(0.02)\n",
    "#     if noise is None:\n",
    "#         noise = tf.random_normal([n_samples, 128])\n",
    "\n",
    "#     labels = tf.cast(labels, tf.float32)\n",
    "#     noise = tf.concat([noise, labels], 1)\n",
    "# #######################\n",
    "#     output = lib.ops.linear.Linear(\"Generator.Input\", 128 + numClasses, 8 * 4 * 4 * dim * 2, noise)  \n",
    "#     output = tf.reshape(output, [-1, 8 * dim * 2, 4, 4])\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN1\", [0, 2, 3], output)\n",
    "#     condition = lib.ops.linear.Linear(\"Generator.cond1\", numClasses, 8 * 4 * 4 * dim * 2, labels, biases=False)\n",
    "#     condition = tf.reshape(condition, [-1, 8 * dim * 2, 4, 4])\n",
    "#     output = pixcnn_gated_nonlinearity(\"Generator.nl1\", 8 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "# #######################\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.2\", 8 * dim, 4 * dim * 2, 5, output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN2\", [0, 2, 3], output)\n",
    "#     condition = lib.ops.linear.Linear(\"Generator.cond2\", numClasses, 4 * 8 * 8 * dim * 2, labels)\n",
    "#     condition = tf.reshape(condition, [-1, 4 * dim * 2, 8, 8])\n",
    "#     output = pixcnn_gated_nonlinearity(\"Generator.nl2\", 4 * dim,output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "# #######################\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.3\", 4 * dim, 2 * dim * 2, 5, output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN3\", [0, 2, 3], output)\n",
    "#     condition = lib.ops.linear.Linear(\"Generator.cond3\", numClasses, 2 * 16 * 16 * dim * 2, labels)\n",
    "#     condition = tf.reshape(condition, [-1, 2 * dim * 2, 16, 16])\n",
    "#     output = pixcnn_gated_nonlinearity( \"Generator.nl3\", 2 * dim,output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "# #######################\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.4\", 2 * dim, dim * 2, 5, output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN4\", [0, 2, 3], output)\n",
    "#     condition = lib.ops.linear.Linear(\"Generator.cond4\", numClasses, 32 * 32 * dim * 2, labels)\n",
    "#     condition = tf.reshape(condition, [-1, 2 * dim, 32, 32])\n",
    "#     output = pixcnn_gated_nonlinearity(\"Generator.nl4\", dim,output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "# #######################\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.5\", dim, 3, 5, output)\n",
    "#     output = tf.tanh(output)\n",
    "#     lib.ops.conv2d.unset_weights_stdev()\n",
    "#     lib.ops.deconv2d.unset_weights_stdev()\n",
    "#     lib.ops.linear.unset_weights_stdev()\n",
    "\n",
    "#     return tf.reshape(output, [-1, OUTPUT_DIM]), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5e1f970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def kACGANDiscriminator(inputs, numClasses, dim=DIM, bn=True, nonlinearity=LeakyReLU):\n",
    "#     output = tf.reshape(inputs, [-1, 3, dim, dim])\n",
    "\n",
    "#     lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.linear.set_weights_stdev(0.02)\n",
    "\n",
    "#     output = lib.ops.conv2d.Conv2D(\"Discriminator.1\", 3, dim, 5, output, stride=2)\n",
    "#     output = nonlinearity(output)\n",
    "\n",
    "#     output = lib.ops.conv2d.Conv2D(\"Discriminator.2\", dim, 2 * dim, 5, output, stride=2)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN2\", [0, 2, 3], output)\n",
    "#     output = nonlinearity(output)\n",
    "\n",
    "#     output = lib.ops.conv2d.Conv2D(\n",
    "#         \"Discriminator.3\", 2 * dim, 4 * dim, 5, output, stride=2\n",
    "#     )\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN3\", [0, 2, 3], output)\n",
    "#     output = nonlinearity(output)\n",
    "\n",
    "#     output = lib.ops.conv2d.Conv2D(\n",
    "#         \"Discriminator.4\", 4 * dim, 8 * dim, 5, output, stride=2\n",
    "#     )\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN4\", [0, 2, 3], output)\n",
    "#     output = nonlinearity(output)\n",
    "#     finalLayer = tf.reshape(output, [-1, 4 * 4 * 8 * dim])\n",
    "\n",
    "#     sourceOutput = lib.ops.linear.Linear(\n",
    "#         \"Discriminator.sourceOutput\", 4 * 4 * 8 * dim, 1, finalLayer\n",
    "#     )\n",
    "\n",
    "#     classOutput = lib.ops.linear.Linear(\n",
    "#         \"Discriminator.classOutput\", 4 * 4 * 8 * dim, numClasses, finalLayer\n",
    "#     )\n",
    "\n",
    "#     lib.ops.conv2d.unset_weights_stdev()\n",
    "#     lib.ops.deconv2d.unset_weights_stdev()\n",
    "#     lib.ops.linear.unset_weights_stdev()\n",
    "\n",
    "#     return (tf.reshape(sourceOutput, [-1]), tf.reshape(classOutput, [-1, numClasses]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c9f300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def kACGANDiscriminator(inputs, numClasses, dim=DIM, bn=True, nonlinearity=LeakyReLU):\n",
    "#     output = tf.reshape(inputs, [-1, 3, dim, dim])\n",
    "\n",
    "#     lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.linear.set_weights_stdev(0.02)\n",
    "\n",
    "#     output = lib.ops.conv2d.Conv2D(\"Discriminator.1\", 3, dim, 5, output, stride=2)\n",
    "#     output = nonlinearity(output)\n",
    "# ######################\n",
    "#     output = lib.ops.conv2d.Conv2D(\"Discriminator.2\", dim, 2 * dim, 5, output, stride=2)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN2\", [0, 2, 3], output)\n",
    "#     output = nonlinearity(output)\n",
    "# ######################\n",
    "#     output = lib.ops.conv2d.Conv2D(\"Discriminator.3\", 2 * dim, 4 * dim, 5, output, stride=2)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN3\", [0, 2, 3], output)\n",
    "#     output = nonlinearity(output)\n",
    "# ######################\n",
    "#     output = lib.ops.conv2d.Conv2D(\"Discriminator.4\", 4 * dim, 8 * dim, 5, output, stride=2)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN4\", [0, 2, 3], output)\n",
    "#     output = nonlinearity(output)\n",
    "#     finalLayer = tf.reshape(output, [-1, 4 * 4 * 8 * dim])\n",
    "# ######################\n",
    "#     sourceOutput = lib.ops.linear.Linear(\"Discriminator.sourceOutput\", 4 * 4 * 8 * dim, 1, finalLayer)\n",
    "#     classOutput = lib.ops.linear.Linear(\"Discriminator.classOutput\", 4 * 4 * 8 * dim, numClasses, finalLayer)\n",
    "#     lib.ops.conv2d.unset_weights_stdev()\n",
    "#     lib.ops.deconv2d.unset_weights_stdev()\n",
    "#     lib.ops.linear.unset_weights_stdev()\n",
    "#     return (tf.reshape(sourceOutput, [-1]), tf.reshape(classOutput, [-1, numClasses]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d730de54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints removed\n",
    "def kACGANDiscriminator(inputs, numClasses, dim=DIM, bn=True, nonlinearity=LeakyReLU):\n",
    "    output = tf.reshape(inputs, [-1, 3, dim, dim])\n",
    "\n",
    "    lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.linear.set_weights_stdev(0.02)\n",
    "\n",
    "    output = lib.ops.conv2d.Conv2D(\"Discriminator.1\", 3, dim, 5, output, stride=2)\n",
    "    print('Discriminator output 1: ', output)\n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 1 nonlinear: ', output)\n",
    "    print('#######################')\n",
    "######################\n",
    "    output = lib.ops.conv2d.Conv2D(\"Discriminator.2\", dim, 2 * dim, 5, output, stride=2)\n",
    "    print('Discriminator output 2: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Discriminator.BN2\", [0, 2, 3], output)\n",
    "        print('Discriminator output 2 bn: ', output)\n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 2 nonlinear: ', output)\n",
    "    print('#######################')\n",
    "######################\n",
    "    output = lib.ops.conv2d.Conv2D(\n",
    "        \"Discriminator.3\", 2 * dim, 4 * dim, 5, output, stride=2\n",
    "    )\n",
    "    print('Discriminator output 3: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Discriminator.BN3\", [0, 2, 3], output)\n",
    "        print('Discriminator output 3 bn: ', output)\n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 3 nonlinear: ', output)\n",
    "    print('#######################')\n",
    "######################\n",
    "    output = lib.ops.conv2d.Conv2D(\n",
    "        \"Discriminator.4\", 4 * dim, 8 * dim, 5, output, stride=2\n",
    "    )\n",
    "    print('Discriminator output 4: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Discriminator.BN4\", [0, 2, 3], output)\n",
    "        print('Discriminator output 4 bn: ', output)\n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 4 nonlinear: ', output)\n",
    "    finalLayer = tf.reshape(output, [-1, 4 * 4 * 8 * dim])\n",
    "    print('Discriminator output final: ', output)\n",
    "    print('#######################')\n",
    "######################\n",
    "    sourceOutput = lib.ops.linear.Linear(\n",
    "        \"Discriminator.sourceOutput\", 4 * 4 * 8 * dim, 1, finalLayer\n",
    "    )\n",
    "    print('Discriminator source output: ', output)\n",
    "    classOutput = lib.ops.linear.Linear(\n",
    "        \"Discriminator.classOutput\", 4 * 4 * 8 * dim, numClasses, finalLayer\n",
    "    )\n",
    "    print('Discriminator class output: ', output)\n",
    "    print('#######################')\n",
    "    lib.ops.conv2d.unset_weights_stdev()\n",
    "    lib.ops.deconv2d.unset_weights_stdev()\n",
    "    lib.ops.linear.unset_weights_stdev()\n",
    "    print('#######################')\n",
    "    return (tf.reshape(sourceOutput, [-1]), tf.reshape(classOutput, [-1, numClasses]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a9ca178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genRandomLabels(n_samples, numClasses, condition=None):\n",
    "    labels = np.zeros([BATCH_SIZE, CLASSES], dtype=np.float32)\n",
    "    for i in range(n_samples):\n",
    "        if condition is not None:\n",
    "            labelNum = condition\n",
    "        else:\n",
    "            labelNum = randint(0, numClasses - 1)\n",
    "        labels[i, labelNum] = 1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "95c8c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "Generator, Discriminator = GeneratorAndDiscriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5ad51ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/gpu:0']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e86d2ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started ...\n",
      "real_data:  Tensor(\"Reshape_46:0\", shape=(84, 12288), dtype=float32, device=/device:GPU:0)\n",
      "real_labels:  Tensor(\"Reshape_47:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n",
      "generated_labels:  Tensor(\"Reshape_48:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n",
      "sample_labels:  Tensor(\"Reshape_49:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n",
      "Generator output 1:  Tensor(\"Generator.Input_2/BiasAdd:0\", shape=(84, 16384), dtype=float32, device=/device:GPU:0) (84, 16384)\n",
      "Generator output 1 reshape:  Tensor(\"Reshape_50:0\", shape=(84, 1024, 4, 4), dtype=float32, device=/device:GPU:0) (84, 1024, 4, 4)\n",
      "Generator output 1 bn:  Tensor(\"FusedBatchNormV3_8:0\", shape=(84, 1024, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 1 final:  Tensor(\"mul_26:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Structure 1:  512 Tensor(\"strided_slice_69:0\", shape=(84, 256, 4, 4), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_70:0\", shape=(84, 256, 4, 4), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_71:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_72:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Generator output 2:  Tensor(\"Generator.2_2/NHWC_to_NCHW:0\", shape=(84, 512, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 2 bn:  Tensor(\"FusedBatchNormV3_9:0\", shape=(84, 512, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 2 final:  Tensor(\"mul_27:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Structure 2:  256 Tensor(\"strided_slice_77:0\", shape=(84, 128, 8, 8), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_78:0\", shape=(84, 128, 8, 8), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_79:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_80:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Generator output 3:  Tensor(\"Generator.3_2/NHWC_to_NCHW:0\", shape=(84, 256, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 3 bn:  Tensor(\"FusedBatchNormV3_10:0\", shape=(84, 256, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 3 final:  Tensor(\"mul_28:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Structure 3:  128 Tensor(\"strided_slice_85:0\", shape=(84, 64, 16, 16), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_86:0\", shape=(84, 64, 16, 16), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_87:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_88:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Generator output 4:  Tensor(\"Generator.4_2/NHWC_to_NCHW:0\", shape=(84, 128, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 4 bn:  Tensor(\"FusedBatchNormV3_11:0\", shape=(84, 128, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 4 final:  Tensor(\"mul_29:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Structure 4:  64 Tensor(\"strided_slice_93:0\", shape=(84, 32, 32, 32), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_94:0\", shape=(84, 32, 32, 32), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_95:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_96:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Generator output 6:  Tensor(\"Generator.5_2/NHWC_to_NCHW:0\", shape=(84, 3, 64, 64), dtype=float32, device=/device:GPU:0)\n",
      "Generator output final:  Tensor(\"Tanh_14:0\", shape=(84, 3, 64, 64), dtype=float32, device=/device:GPU:0)\n",
      "fake_data:  Tensor(\"Reshape_55:0\", shape=(84, 12288), dtype=float32, device=/device:GPU:0)\n",
      "fake_labels:  Tensor(\"Cast_6:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 1:  Tensor(\"Discriminator.1_3/BiasAdd:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 1 nonlinear:  Tensor(\"Maximum_12:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 2:  Tensor(\"Discriminator.2_3/BiasAdd:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 bn:  Tensor(\"batchnorm_9/add_1:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 nonlinear:  Tensor(\"Maximum_13:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 3:  Tensor(\"Discriminator.3_3/BiasAdd:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 3 bn:  Tensor(\"batchnorm_10/add_1:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 3 nonlinear:  Tensor(\"Maximum_14:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 4:  Tensor(\"Discriminator.4_3/BiasAdd:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 4 bn:  Tensor(\"batchnorm_11/add_1:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 4 nonlinear:  Tensor(\"Maximum_15:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output final:  Tensor(\"Maximum_15:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator source output:  Tensor(\"Maximum_15:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator class output:  Tensor(\"Maximum_15:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "#######################\n",
      "disc fake:  Tensor(\"Reshape_64:0\", shape=(84,), dtype=float32, device=/device:GPU:0) Tensor(\"Reshape_65:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 1:  Tensor(\"Discriminator.1_4/BiasAdd:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 1 nonlinear:  Tensor(\"Maximum_16:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 2:  Tensor(\"Discriminator.2_4/BiasAdd:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 bn:  Tensor(\"batchnorm_12/add_1:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 nonlinear:  Tensor(\"Maximum_17:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 3:  Tensor(\"Discriminator.3_4/BiasAdd:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 3 bn:  Tensor(\"batchnorm_13/add_1:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 3 nonlinear:  Tensor(\"Maximum_18:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 4:  Tensor(\"Discriminator.4_4/BiasAdd:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 4 bn:  Tensor(\"batchnorm_14/add_1:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 4 nonlinear:  Tensor(\"Maximum_19:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output final:  Tensor(\"Maximum_19:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator source output:  Tensor(\"Maximum_19:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator class output:  Tensor(\"Maximum_19:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "#######################\n",
      "disc real:  Tensor(\"Reshape_74:0\", shape=(84,), dtype=float32, device=/device:GPU:0) Tensor(\"Reshape_75:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "prediction 1:  Tensor(\"ArgMax_4:0\", shape=(84,), dtype=int64, device=/device:GPU:0) Tensor(\"Reshape_65:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "correct 1:  Tensor(\"ArgMax_5:0\", shape=(84,), dtype=int64, device=/device:GPU:0) Tensor(\"Cast_6:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "equality 1:  Tensor(\"Equal_2:0\", shape=(84,), dtype=bool, device=/device:GPU:0)\n",
      "accuracy 1:  Tensor(\"Mean_11:0\", shape=(), dtype=float32, device=/device:GPU:0)\n",
      "prediction 2:  Tensor(\"ArgMax_6:0\", shape=(84,), dtype=int64, device=/device:GPU:0)\n",
      "disc real class:  Tensor(\"Reshape_75:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "correct 2:  Tensor(\"ArgMax_7:0\", shape=(84,), dtype=int64, device=/device:GPU:0) Tensor(\"Reshape_47:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n",
      "equality 2:  Tensor(\"Equal_3:0\", shape=(84,), dtype=bool, device=/device:GPU:0)\n",
      "Discriminator output 1:  Tensor(\"Discriminator.1_5/BiasAdd:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 1 nonlinear:  Tensor(\"Maximum_20:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 2:  Tensor(\"Discriminator.2_5/BiasAdd:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 bn:  Tensor(\"batchnorm_15/add_1:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 nonlinear:  Tensor(\"Maximum_21:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 3:  Tensor(\"Discriminator.3_5/BiasAdd:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 3 bn:  Tensor(\"batchnorm_16/add_1:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 3 nonlinear:  Tensor(\"Maximum_22:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 4:  Tensor(\"Discriminator.4_5/BiasAdd:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 4 bn:  Tensor(\"batchnorm_17/add_1:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 4 nonlinear:  Tensor(\"Maximum_23:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output final:  Tensor(\"Maximum_23:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator source output:  Tensor(\"Maximum_23:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator class output:  Tensor(\"Maximum_23:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "#######################\n",
      "Generator output 1:  Tensor(\"Generator.Input_3/BiasAdd:0\", shape=(84, 16384), dtype=float32) (84, 16384)\n",
      "Generator output 1 reshape:  Tensor(\"Reshape_86:0\", shape=(84, 1024, 4, 4), dtype=float32) (84, 1024, 4, 4)\n",
      "Generator output 1 bn:  Tensor(\"FusedBatchNormV3_12:0\", shape=(84, 1024, 4, 4), dtype=float32)\n",
      "Generator output 1 final:  Tensor(\"mul_46:0\", shape=(84, 512, 4, 4), dtype=float32)\n",
      "Structure 1:  512 Tensor(\"strided_slice_102:0\", shape=(84, 256, 4, 4), dtype=float32) Tensor(\"strided_slice_103:0\", shape=(84, 256, 4, 4), dtype=float32) Tensor(\"strided_slice_104:0\", shape=(84, 512, 4, 4), dtype=float32) Tensor(\"strided_slice_105:0\", shape=(84, 512, 4, 4), dtype=float32)\n",
      "#######################\n",
      "Generator output 2:  Tensor(\"Generator.2_3/NHWC_to_NCHW:0\", shape=(84, 512, 8, 8), dtype=float32)\n",
      "Generator output 2 bn:  Tensor(\"FusedBatchNormV3_13:0\", shape=(84, 512, 8, 8), dtype=float32)\n",
      "Generator output 2 final:  Tensor(\"mul_47:0\", shape=(84, 256, 8, 8), dtype=float32)\n",
      "Structure 2:  256 Tensor(\"strided_slice_110:0\", shape=(84, 128, 8, 8), dtype=float32) Tensor(\"strided_slice_111:0\", shape=(84, 128, 8, 8), dtype=float32) Tensor(\"strided_slice_112:0\", shape=(84, 256, 8, 8), dtype=float32) Tensor(\"strided_slice_113:0\", shape=(84, 256, 8, 8), dtype=float32)\n",
      "#######################\n",
      "Generator output 3:  Tensor(\"Generator.3_3/NHWC_to_NCHW:0\", shape=(84, 256, 16, 16), dtype=float32)\n",
      "Generator output 3 bn:  Tensor(\"FusedBatchNormV3_14:0\", shape=(84, 256, 16, 16), dtype=float32)\n",
      "Generator output 3 final:  Tensor(\"mul_48:0\", shape=(84, 128, 16, 16), dtype=float32)\n",
      "Structure 3:  128 Tensor(\"strided_slice_118:0\", shape=(84, 64, 16, 16), dtype=float32) Tensor(\"strided_slice_119:0\", shape=(84, 64, 16, 16), dtype=float32) Tensor(\"strided_slice_120:0\", shape=(84, 128, 16, 16), dtype=float32) Tensor(\"strided_slice_121:0\", shape=(84, 128, 16, 16), dtype=float32)\n",
      "#######################\n",
      "Generator output 4:  Tensor(\"Generator.4_3/NHWC_to_NCHW:0\", shape=(84, 128, 32, 32), dtype=float32)\n",
      "Generator output 4 bn:  Tensor(\"FusedBatchNormV3_15:0\", shape=(84, 128, 32, 32), dtype=float32)\n",
      "Generator output 4 final:  Tensor(\"mul_49:0\", shape=(84, 64, 32, 32), dtype=float32)\n",
      "Structure 4:  64 Tensor(\"strided_slice_126:0\", shape=(84, 32, 32, 32), dtype=float32) Tensor(\"strided_slice_127:0\", shape=(84, 32, 32, 32), dtype=float32) Tensor(\"strided_slice_128:0\", shape=(84, 64, 32, 32), dtype=float32) Tensor(\"strided_slice_129:0\", shape=(84, 64, 32, 32), dtype=float32)\n",
      "#######################\n",
      "Generator output 6:  Tensor(\"Generator.5_3/NHWC_to_NCHW:0\", shape=(84, 3, 64, 64), dtype=float32)\n",
      "Generator output final:  Tensor(\"Tanh_19:0\", shape=(84, 3, 64, 64), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "pretraining accuracy: 0.77380955\n",
      "pretraining accuracy: 0.88095236\n",
      "pretraining accuracy: 0.79761904\n",
      "pretraining accuracy: 0.6547619\n",
      "pretraining accuracy: 0.7619048\n",
      "pretraining accuracy: 0.70238096\n",
      "pretraining accuracy: 0.61904764\n",
      "pretraining accuracy: 0.64285713\n",
      "pretraining accuracy: 0.78571427\n",
      "pretraining accuracy: 0.72619045\n",
      "pretraining accuracy: 0.7619048\n",
      "pretraining accuracy: 0.6785714\n",
      "pretraining accuracy: 0.72619045\n",
      "pretraining accuracy: 0.6904762\n",
      "pretraining accuracy: 0.78571427\n",
      "pretraining accuracy: 0.70238096\n",
      "pretraining accuracy: 0.6904762\n",
      "pretraining accuracy: 0.70238096\n",
      "pretraining accuracy: 0.70238096\n",
      "pretraining accuracy: 0.6904762\n",
      "iter 0\ttrain disc cost\t-93.61474609375\ttime\t4.823342561721802\twgan train disc cost\t-132.19287109375\ttrain class cost\t0.50090092420578\tgenerated class cost\t3.397813081741333\tgen cost cost\t42.7982177734375\tgen accuracy\t0.5476190447807312\treal accuracy\t0.7142857313156128\n",
      "iter 1\ttrain disc cost\t-77.04358673095703\ttime\t2.7215793132781982\twgan train disc cost\t-128.76528930664062\ttrain class cost\t0.5441814661026001\tgenerated class cost\t3.7058298587799072\tgen cost cost\t47.332618713378906\tgen accuracy\t0.511904776096344\treal accuracy\t0.773809552192688\n",
      "iter 2\ttrain disc cost\t-83.72035217285156\ttime\t1.343337059020996\twgan train disc cost\t-141.826171875\ttrain class cost\t0.5444506406784058\tgenerated class cost\t4.745082855224609\tgen cost cost\t52.73500442504883\tgen accuracy\t0.4404761791229248\treal accuracy\t0.75\n",
      "iter 3\ttrain disc cost\t-76.03640747070312\ttime\t1.3259880542755127\twgan train disc cost\t-130.1155242919922\ttrain class cost\t0.5154852867126465\tgenerated class cost\t3.439622402191162\tgen cost cost\t37.26758575439453\tgen accuracy\t0.511904776096344\treal accuracy\t0.761904776096344\n",
      "iter 4\ttrain disc cost\t-79.22212982177734\ttime\t1.3319694995880127\twgan train disc cost\t-136.5228271484375\ttrain class cost\t0.49040257930755615\tgenerated class cost\t3.7682642936706543\tgen cost cost\t51.20497512817383\tgen accuracy\t0.511904776096344\treal accuracy\t0.773809552192688\n",
      "iter 5\ttrain disc cost\t-98.02903747558594\ttime\t1.3283348083496094\twgan train disc cost\t-151.49932861328125\ttrain class cost\t0.6445496082305908\tgenerated class cost\t3.6656370162963867\tgen cost cost\t49.31222152709961\tgen accuracy\t0.5714285969734192\treal accuracy\t0.6309523582458496\n",
      "iter 6\ttrain disc cost\t-67.19991302490234\ttime\t1.3329448699951172\twgan train disc cost\t-109.10018920898438\ttrain class cost\t0.4710530638694763\tgenerated class cost\t3.0123655796051025\tgen cost cost\t26.617324829101562\tgen accuracy\t0.5714285969734192\treal accuracy\t0.8095238208770752\n",
      "iter 7\ttrain disc cost\t-77.36163330078125\ttime\t1.3300974369049072\twgan train disc cost\t-121.01611328125\ttrain class cost\t0.529633641242981\tgenerated class cost\t3.907829761505127\tgen cost cost\t42.89713668823242\tgen accuracy\t0.5476190447807312\treal accuracy\t0.75\n",
      "iter 8\ttrain disc cost\t-84.84576416015625\ttime\t1.3285980224609375\twgan train disc cost\t-139.7974090576172\ttrain class cost\t0.6549295783042908\tgenerated class cost\t4.4032769203186035\tgen cost cost\t50.258853912353516\tgen accuracy\t0.5714285969734192\treal accuracy\t0.6785714030265808\n",
      "iter 9\ttrain disc cost\t-75.32054138183594\ttime\t1.3378591537475586\twgan train disc cost\t-153.16650390625\ttrain class cost\t0.5869027376174927\tgenerated class cost\t5.339095115661621\tgen cost cost\t34.41581726074219\tgen accuracy\t0.4285714328289032\treal accuracy\t0.6904761791229248\n",
      "iter 99\ttrain disc cost\t-37.40135955810547\ttime\t1.3489061991373699\twgan train disc cost\t-55.332374572753906\ttrain class cost\t0.48378846049308777\tgenerated class cost\t1.2994780540466309\tgen cost cost\t52.671295166015625\tgen accuracy\t0.5546296238899231\treal accuracy\t0.7596560716629028\tdev disc cost\t-17.99199676513672\twgan dev disc cost\t-25.355091094970703\tdev class cost\t0.4037397503852844\tdev generated class cost\t0.6768972277641296\tdev gen  cost\t66.31580352783203\tdev gen accuracy\t0.6309523582458496\tdev real accuracy\t0.8333333134651184\n",
      "iter 199\ttrain disc cost\t-19.02231788635254\ttime\t1.3531931519508362\twgan train disc cost\t-26.058759689331055\ttrain class cost\t0.4062284231185913\tgenerated class cost\t0.6444947123527527\tgen cost cost\t28.014135360717773\tgen accuracy\t0.6759523153305054\treal accuracy\t0.8123809099197388\tdev disc cost\t-17.033536911010742\twgan dev disc cost\t-21.59516716003418\tdev class cost\t0.45871207118034363\tdev generated class cost\t0.515392541885376\tdev gen  cost\t35.70161819458008\tdev gen accuracy\t0.773809552192688\tdev real accuracy\t0.761904776096344\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-6bf3145cd853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0mall_real_data_conv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                     \u001b[0mall_real_label_conv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                     \u001b[0mgenerated_labels_conv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgenRandomLabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m                 },\n\u001b[1;32m    247\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as session:\n",
    "    print('started ...')\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    all_real_data_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, 3, DIM, DIM])\n",
    "    all_real_label_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, CLASSES])\n",
    "\n",
    "    generated_labels_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, CLASSES])\n",
    "    sample_labels_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, CLASSES])\n",
    "\n",
    "    split_real_data_conv = tf.split(all_real_data_conv, len(DEVICES))\n",
    "    split_real_label_conv = tf.split(all_real_label_conv, len(DEVICES))\n",
    "    split_generated_labels_conv = tf.split(generated_labels_conv, len(DEVICES))\n",
    "    split_sample_labels_conv = tf.split(sample_labels_conv, len(DEVICES))\n",
    "\n",
    "    gen_costs, disc_costs = [], []\n",
    "\n",
    "    for device_index, (device, real_data_conv, real_label_conv) in enumerate(\n",
    "        zip(DEVICES, split_real_data_conv, split_real_label_conv)\n",
    "    ):\n",
    "        with tf.device(device):\n",
    "\n",
    "            real_data = tf.reshape(\n",
    "                2 * ((tf.cast(real_data_conv, tf.float32) / 255.0) - 0.5),\n",
    "                [BATCH_SIZE // len(DEVICES), OUTPUT_DIM],\n",
    "            )\n",
    "            print('real_data: ', real_data)\n",
    "            real_labels = tf.reshape(\n",
    "                real_label_conv, [BATCH_SIZE // len(DEVICES), CLASSES]\n",
    "            )\n",
    "            print('real_labels: ', real_labels)\n",
    "            generated_labels = tf.reshape(\n",
    "                split_generated_labels_conv, [BATCH_SIZE // len(DEVICES), CLASSES]\n",
    "            )\n",
    "            print('generated_labels: ', generated_labels)\n",
    "            sample_labels = tf.reshape(\n",
    "                split_sample_labels_conv, [BATCH_SIZE // len(DEVICES), CLASSES]\n",
    "            )\n",
    "            print('sample_labels: ', sample_labels)\n",
    "            fake_data, fake_labels = Generator(\n",
    "                BATCH_SIZE // len(DEVICES), CLASSES, generated_labels\n",
    "            )\n",
    "#             print(real_data,real_labels,generated_labels,sample_labels,fake_data, fake_labels)\n",
    "            print('fake_data: ', fake_data)\n",
    "            print('fake_labels: ', fake_labels)\n",
    "            # set up discrimnator results\n",
    "\n",
    "            disc_fake, disc_fake_class = Discriminator(fake_data, CLASSES)\n",
    "            print('disc fake: ', disc_fake, disc_fake_class)\n",
    "            disc_real, disc_real_class = Discriminator(real_data, CLASSES)\n",
    "            print('disc real: ', disc_real, disc_real_class)\n",
    "            prediction = tf.argmax(disc_fake_class, 1)\n",
    "            print('prediction 1: ', prediction, disc_fake_class)\n",
    "            correct_answer = tf.argmax(fake_labels, 1)\n",
    "            print('correct 1: ', correct_answer, fake_labels)\n",
    "            equality = tf.equal(prediction, correct_answer)\n",
    "            print('equality 1: ', equality)\n",
    "            genAccuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "            print('accuracy 1: ', genAccuracy)\n",
    "            \n",
    "            prediction = tf.argmax(disc_real_class, 1)\n",
    "            print('prediction 2: ', prediction)\n",
    "            print('disc real class: ', disc_real_class)\n",
    "            correct_answer = tf.argmax(real_labels, 1)\n",
    "            print('correct 2: ', correct_answer, real_labels)\n",
    "#             equality = tf.equal(correct_answer, prediction)\n",
    "            equality = tf.equal(prediction, correct_answer)\n",
    "            print('equality 2: ', equality)\n",
    "            realAccuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "\n",
    "            gen_cost = -tf.reduce_mean(disc_fake)\n",
    "            disc_cost = tf.reduce_mean(disc_fake) - tf.reduce_mean(disc_real)\n",
    "\n",
    "            gen_cost_test = -tf.reduce_mean(disc_fake)\n",
    "            disc_cost_test = tf.reduce_mean(disc_fake) - tf.reduce_mean(disc_real)\n",
    "\n",
    "            generated_class_cost = tf.reduce_mean(\n",
    "                tf.nn.softmax_cross_entropy_with_logits(\n",
    "                    logits=disc_fake_class, labels=fake_labels\n",
    "                )\n",
    "            )\n",
    "\n",
    "            real_class_cost = tf.reduce_mean(\n",
    "                tf.nn.softmax_cross_entropy_with_logits(\n",
    "                    logits=disc_real_class, labels=real_labels\n",
    "                )\n",
    "            )\n",
    "            gen_cost += generated_class_cost\n",
    "            disc_cost += real_class_cost\n",
    "\n",
    "            alpha = tf.random_uniform(\n",
    "                shape=[BATCH_SIZE // len(DEVICES), 1], minval=0.0, maxval=1.0\n",
    "            )\n",
    "            differences = fake_data - real_data\n",
    "            interpolates = real_data + (alpha * differences)\n",
    "            gradients = tf.gradients(\n",
    "                Discriminator(interpolates, CLASSES)[0], [interpolates]\n",
    "            )[0]\n",
    "            slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "            gradient_penalty = tf.reduce_mean((slopes - 1.0) ** 2)\n",
    "            disc_cost += LAMBDA * gradient_penalty\n",
    "\n",
    "            real_class_cost_gradient = real_class_cost * 50 + LAMBDA * gradient_penalty\n",
    "\n",
    "            gen_costs.append(gen_cost)\n",
    "            disc_costs.append(disc_cost)\n",
    "\n",
    "    gen_cost = tf.add_n(gen_costs) / len(DEVICES)\n",
    "    disc_cost = tf.add_n(disc_costs) / len(DEVICES)\n",
    "\n",
    "    gen_train_op = tf.train.AdamOptimizer(\n",
    "        learning_rate=1e-4, beta1=0.5, beta2=0.9\n",
    "    ).minimize(\n",
    "        gen_cost,\n",
    "        var_list=lib.params_with_name(\"Generator\"),\n",
    "        colocate_gradients_with_ops=True,\n",
    "    )\n",
    "    disc_train_op = tf.train.AdamOptimizer(\n",
    "        learning_rate=1e-4, beta1=0.5, beta2=0.9\n",
    "    ).minimize(\n",
    "        disc_cost,\n",
    "        var_list=lib.params_with_name(\"Discriminator.\"),\n",
    "        colocate_gradients_with_ops=True,\n",
    "    )\n",
    "    class_train_op = tf.train.AdamOptimizer(\n",
    "        learning_rate=1e-4, beta1=0.5, beta2=0.9\n",
    "    ).minimize(\n",
    "        real_class_cost_gradient,\n",
    "        var_list=lib.params_with_name(\"Discriminator.\"),\n",
    "        colocate_gradients_with_ops=True,\n",
    "    )\n",
    "    # For generating samples\n",
    "\n",
    "    fixed_noise = tf.constant(\n",
    "        np.random.normal(size=(BATCH_SIZE, 128)).astype(\"float32\")\n",
    "    )\n",
    "    all_fixed_noise_samples = []\n",
    "    for device_index, device in enumerate(DEVICES):\n",
    "        n_samples = BATCH_SIZE // len(DEVICES)\n",
    "        all_fixed_noise_samples.append(\n",
    "            Generator(\n",
    "                n_samples,\n",
    "                CLASSES,\n",
    "                sample_labels,\n",
    "                noise=fixed_noise[\n",
    "                    device_index * n_samples : (device_index + 1) * n_samples\n",
    "                ],\n",
    "            )[0]\n",
    "        )\n",
    "        if tf.__version__.startswith(\"1.\"):\n",
    "            all_fixed_noise_samples = tf.concat(all_fixed_noise_samples, axis=0)\n",
    "        else:\n",
    "            all_fixed_noise_samples = tf.concat(0, all_fixed_noise_samples)\n",
    "\n",
    "    def generate_image(iteration):\n",
    "        # this might be where we add the conditionality\n",
    "        for i in range(CLASSES):\n",
    "            curLabel = genRandomLabels(BATCH_SIZE, CLASSES, condition=i)\n",
    "            samples = session.run(\n",
    "                all_fixed_noise_samples, feed_dict={sample_labels: curLabel}\n",
    "            )\n",
    "            samples = ((samples + 1.0) * (255.99 / 2)).astype(\"int32\")\n",
    "            lib.save_images.save_images(\n",
    "                samples.reshape((BATCH_SIZE, 3, DIM, DIM)),\n",
    "                \"generated/samples_{}_{}.png\".format(str(i), iteration),\n",
    "            )\n",
    "\n",
    "    # Dataset iterator\n",
    "#     train_gen, dev_gen = lib.wikiart_genre.load(BATCH_SIZE)\n",
    "    train_gen, dev_gen = load(BATCH_SIZE)\n",
    "\n",
    "    def softmax_cross_entropy(logit, y):\n",
    "        return -tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=y)\n",
    "        )\n",
    "\n",
    "    def inf_train_gen():\n",
    "        while True:\n",
    "            for (images, labels) in train_gen():\n",
    "                yield images, labels\n",
    "\n",
    "    _sample_labels = genRandomLabels(BATCH_SIZE, CLASSES)\n",
    "    # Save a batch of ground-truth samples\n",
    "    _x, _y = next(train_gen())\n",
    "    _x_r = session.run(real_data, feed_dict={all_real_data_conv: _x})\n",
    "    _x_r = ((_x_r + 1.0) * (255.99 / 2)).astype(\"int32\")\n",
    "    lib.save_images.save_images(\n",
    "        _x_r.reshape((BATCH_SIZE, 3, DIM, DIM)), \"generated/samples_groundtruth.png\"\n",
    "    )\n",
    "\n",
    "    session.run(\n",
    "        tf.initialize_all_variables(),\n",
    "        feed_dict={generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES)},\n",
    "    )\n",
    "    gen = train_gen()\n",
    "\n",
    "    for iterp in range(PREITERATIONS):\n",
    "        _data, _labels = next(gen)\n",
    "        _, accuracy = session.run(\n",
    "            [disc_train_op, realAccuracy],\n",
    "            feed_dict={\n",
    "                all_real_data_conv: _data,\n",
    "                all_real_label_conv: _labels,\n",
    "                generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES),\n",
    "            },\n",
    "        )\n",
    "        if iterp % 100 == 99:\n",
    "            print(\"pretraining accuracy: \" + str(accuracy))\n",
    "\n",
    "    for iteration in range(ITERS):\n",
    "        start_time = time.time()\n",
    "        # Train generator\n",
    "        if iteration > 0:\n",
    "            _ = session.run(\n",
    "                gen_train_op,\n",
    "                feed_dict={generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES)},\n",
    "            )\n",
    "        # Train critic\n",
    "        disc_iters = CRITIC_ITERS\n",
    "        for i in range(disc_iters):\n",
    "            _data, _labels = next(gen)\n",
    "            (\n",
    "                _disc_cost,\n",
    "                _disc_cost_test,\n",
    "                class_cost_test,\n",
    "                gen_class_cost,\n",
    "                _gen_cost_test,\n",
    "                _genAccuracy,\n",
    "                _realAccuracy,\n",
    "                _,\n",
    "            ) = session.run(\n",
    "                [\n",
    "                    disc_cost,\n",
    "                    disc_cost_test,\n",
    "                    real_class_cost,\n",
    "                    generated_class_cost,\n",
    "                    gen_cost_test,\n",
    "                    genAccuracy,\n",
    "                    realAccuracy,\n",
    "                    disc_train_op,\n",
    "                ],\n",
    "                feed_dict={\n",
    "                    all_real_data_conv: _data,\n",
    "                    all_real_label_conv: _labels,\n",
    "                    generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES),\n",
    "                },\n",
    "            )\n",
    "\n",
    "        lib.plot.plot(\"train disc cost\", _disc_cost)\n",
    "        lib.plot.plot(\"time\", time.time() - start_time)\n",
    "        lib.plot.plot(\"wgan train disc cost\", _disc_cost_test)\n",
    "        lib.plot.plot(\"train class cost\", class_cost_test)\n",
    "        lib.plot.plot(\"generated class cost\", gen_class_cost)\n",
    "        lib.plot.plot(\"gen cost cost\", _gen_cost_test)\n",
    "        lib.plot.plot(\"gen accuracy\", _genAccuracy)\n",
    "        lib.plot.plot(\"real accuracy\", _realAccuracy)\n",
    "\n",
    "        if (iteration % 100 == 99 and iteration < 1000) or iteration % 1000 == 999:\n",
    "            t = time.time()\n",
    "            dev_disc_costs = []\n",
    "            images, labels = next(dev_gen())\n",
    "            (\n",
    "                _dev_disc_cost,\n",
    "                _dev_disc_cost_test,\n",
    "                _class_cost_test,\n",
    "                _gen_class_cost,\n",
    "                _dev_gen_cost_test,\n",
    "                _dev_genAccuracy,\n",
    "                _dev_realAccuracy,\n",
    "            ) = session.run(\n",
    "                [\n",
    "                    disc_cost,\n",
    "                    disc_cost_test,\n",
    "                    real_class_cost,\n",
    "                    generated_class_cost,\n",
    "                    gen_cost_test,\n",
    "                    genAccuracy,\n",
    "                    realAccuracy,\n",
    "                ],\n",
    "                feed_dict={\n",
    "                    all_real_data_conv: images,\n",
    "                    all_real_label_conv: labels,\n",
    "                    generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES),\n",
    "                },\n",
    "            )\n",
    "            dev_disc_costs.append(_dev_disc_cost)\n",
    "            lib.plot.plot(\"dev disc cost\", np.mean(dev_disc_costs))\n",
    "            lib.plot.plot(\"wgan dev disc cost\", _dev_disc_cost_test)\n",
    "            lib.plot.plot(\"dev class cost\", _class_cost_test)\n",
    "            lib.plot.plot(\"dev generated class cost\", _gen_class_cost)\n",
    "            lib.plot.plot(\"dev gen  cost\", _dev_gen_cost_test)\n",
    "            lib.plot.plot(\"dev gen accuracy\", _dev_genAccuracy)\n",
    "            lib.plot.plot(\"dev real accuracy\", _dev_realAccuracy)\n",
    "\n",
    "        if iteration % 100 == 999:\n",
    "            generate_image(iteration)\n",
    "            # Can add generate_good_images method in here if desired\n",
    "\n",
    "        if (iteration < 10) or (iteration % 100 == 99):\n",
    "            lib.plot.flush()\n",
    "\n",
    "        lib.plot.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a687a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7497959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc87f8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
